{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOLIMAN Pupil Gluing Analysis: Preliminary Measurements\n",
    "\n",
    "**Aim:**  \n",
    "To determine:\n",
    "1. The optical aberrations induced by the lab setup for pupil testing (consisting of 2 OAPs)\n",
    "2. The intensity distribution ouput from the optical fiber output for later modelling\n",
    "\n",
    "If we can show these aberrations are static over a long enough period of time (> 30min) then we can confidently remove them from the phase retrieval analysis of the later measurements (glued vs non-glued).\n",
    "\n",
    "We have chosen to place a spider mask (necessary asymmetry) within the collimated beam to characterise these aberrations via phase retrieval (thank u differentiable modelling/dLux 💖)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dLux as dl\n",
    "import dLux.utils as dlu\n",
    "\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import jax.random as jr\n",
    "import jax.scipy as jsp\n",
    "from jax import vmap  \n",
    "\n",
    "import zodiax as zdx\n",
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.filters import window\n",
    "import skimage as ski\n",
    "from skimage.transform import resize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import PowerNorm\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"image.origin\"] = 'lower'\n",
    "plt.rcParams['figure.dpi'] = 72\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "plt.rcParams[\"axes.titlesize\"] = 18\n",
    "plt.rcParams[\"figure.titlesize\"] = 18\n",
    "plt.rcParams[\"axes.labelsize\"] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Physical Parameters ---------------------------------------------------------------------#\n",
    "aperture_npix = 512           # Number of pixels across the aperture\n",
    "aperture_diameter = 126e-3    # (m)\n",
    "spider_width = 20e-3          # Spider width (m)\n",
    "spider_angle =270             # Spider angle (degrees), clockwise, 0 is spider pointing vertically up\n",
    "coords = dlu.pixel_coords(npixels=aperture_npix, diameter=aperture_diameter)\n",
    "circle = dlu.circle(coords=coords, radius=aperture_diameter/2) \n",
    "\n",
    "# Observations wavelengths (bandpass of 530-640nm)\n",
    "wavelengths = np.linspace(530e-9, 640e-9, 100)  # Wavelengths to simulate (m)\n",
    "laser_wavelength =  635e-09  # for laser data\n",
    "wf_npixels = aperture_npix  # Number of pixels across the wavefront\n",
    "wf_diam = aperture_diameter             # Diameter of initial wavefront to propagate wavefront (m)\n",
    "\n",
    "# Dtector parameters (BFS-U3-200S6-BD)\n",
    "BFS_px_sep = 2.4e-6 *1e3        # pixel separation (mm)\n",
    "f_det = 1300#1350                    # Focal length from OAP2 to detector (mm) \n",
    "px_ang_sep = 2*np.arctan( (BFS_px_sep/2)/f_det ) # angular sep between pixels (rad)\n",
    "\n",
    "# Simulated Detector\n",
    "psf_npix = 40                 # Number of pixels along one dim of the PSF\n",
    "oversample = 1                 # Oversampling factor for the PSF\n",
    "psf_pixel_scale = dlu.rad2arcsec(px_ang_sep) # arcsec (to match detector plate scale) 80e-4 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in some ✨real✨ data 🌈\n",
    "- Check intensity distribution across pupil first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/intensity/15_07_intensity_dist.png\"\n",
    "data = imread(fname, as_gray=True) \n",
    "manual_lim = [1363,4203,386,3214]\n",
    "data = data[manual_lim[2]:manual_lim[3], manual_lim[0]:manual_lim[1]]\n",
    "data = (data - data.min())/(data.max()-data.min())\n",
    "\n",
    "blurred = ski.filters.gaussian(data, sigma=(120, 120))\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(data)\n",
    "plt.title(\"Data - pre-focus\")\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(blurred)\n",
    "plt.title(\"Data blurred\")\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,3)\n",
    "intensity_dist = resize(blurred, (aperture_npix, aperture_npix))\n",
    "intensity_dist = (intensity_dist - intensity_dist.min())/(intensity_dist.max()-intensity_dist.min()) # re-map from 0-1\n",
    "# intensity_dist = np.fliplr(intensity_dist)\n",
    "plt.title(\"Blurred re-sized\")\n",
    "plt.imshow(intensity_dist)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 2D gaussian to approximate this\n",
    "def gauss_2d(x_0, y_0, var_x, var_y, envelope, pixel_coords):\n",
    "    \"\"\"\n",
    "        Output 2D gaussian array with amplitude of 1, within\n",
    "        aperture profile.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        x_0, y_0 : float\n",
    "            (x,y) coordinate of the center of the gaussian (m)\n",
    "        var_x, var_y : float\n",
    "            Variance in the x and y directions (m)\n",
    "        envelope : ndarray\n",
    "            2D array of the aperture profile. Where this is 0, the gaussian\n",
    "            is ommitted, where this is 1, the gaussian is included.\n",
    "        pixel_coords : ndarray\n",
    "            3D array of pixel coordinates over which gaussian is defined in the shape\n",
    "            (2, npix, npix) where npix is the number of pixels across one dimension of the\n",
    "            each 2D array (one for X and Y).\n",
    "    \"\"\"\n",
    "    X, Y = pixel_coords\n",
    "    assert X.shape[0] == envelope.shape[0], \"Envelope and pixel coords must have the same shape\"\n",
    "\n",
    "    z = jnp.exp(-(X - x_0)**2/(2*var_x**2) - (Y - y_0)**2/(2*var_y**2))\n",
    "\n",
    "    return z * envelope\n",
    "\n",
    "var = 0.05\n",
    "test = gauss_2d(x_0=0, y_0=0, var_x=var, var_y=var, envelope=circle, pixel_coords=coords)\n",
    "plt.imshow(test)\n",
    "plt.title(\"Approximated WF intensity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dLux class for this gauss transmissive layer\n",
    "# maybe modelling a source object would be easier?\n",
    "class GaussTransmissiveLayer(dl.layers.optical_layers.TransmissiveLayer):\n",
    "    \"\"\"\n",
    "        Inherits from dl.layers.TransmissiveLayerm and allows for\n",
    "        a Gaussian transmissive layer to be simulated. Useful for \n",
    "        simulating a wavefront that is not uniform in intensity.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        transmission: Array\n",
    "            The Array of transmission values to be applied to the input wavefront.\n",
    "        gaussian_param: Array = [x_0, y_0, var_x, var_y], shape (4,)\n",
    "            The parameters defining the 2D Gaussian to be applied to the input wavefront.\n",
    "            Where:\n",
    "            x_0, y_0 = float\n",
    "                (x,y) coordinate of the center of the gaussian (m)\n",
    "            var_x, var_y = float\n",
    "                Variance in the x and y directions (m)\n",
    "        envelope: Array\n",
    "            2D array of the aperture profile. This masks out the Gaussian where the envelope\n",
    "            is 0 and includes it where the envelope is 1. \n",
    "        pixel_coords : Array\n",
    "            3D array of pixel coordinates over which gaussian is defined in the shape\n",
    "            (2, npix, npix) where npix is the number of pixels across one dimension of the\n",
    "            each 2D array (one for X and Y).\n",
    "        normalise: bool\n",
    "            Whether to normalise the wavefront after passing through the optic.\n",
    "    \"\"\"\n",
    "    envelope: jnp.array\n",
    "    X: jnp.array\n",
    "    Y: jnp.array\n",
    "\n",
    "    gauss_param: jnp.array\n",
    "\n",
    "    def __init__(\n",
    "        self: dl.layers.optical_layers.OpticalLayer,\n",
    "        gaussian_param: np.array,\n",
    "        envelope: np.array,\n",
    "        pixel_coords: np.array,\n",
    "        normalise: bool = False,\n",
    "    ):\n",
    "        self.X, self.Y = pixel_coords\n",
    "        assert self.X.shape[0] == envelope.shape[0], \"Envelope and pixel coords must have the same shape\"\n",
    "        assert gaussian_param.shape == (4,), \"Gaussian parameters must be of shape (4,) in form [x_0, y_0, var_x, var_y] \"\n",
    "        self.gauss_param = gaussian_param\n",
    "        self.envelope = envelope\n",
    "\n",
    "        z = jnp.exp(-(self.X - self.gauss_param[0])**2/(2*self.gauss_param[2]**2) - (self.Y - self.gauss_param[1])**2/(2*self.gauss_param[3]**2))\n",
    "        self.transmission = z * self.envelope\n",
    "\n",
    "        super().__init__(transmission=self.transmission, normalise=normalise)\n",
    "\n",
    "    def get_transmission(self):\n",
    "        z = jnp.exp(-(self.X - self.gauss_param[0])**2/(2*self.gauss_param[2]**2) - (self.Y - self.gauss_param[1])**2/(2*self.gauss_param[3]**2))\n",
    "\n",
    "        return z * self.envelope\n",
    "\n",
    "    def apply(self: dl.layers.optical_layers.OpticalLayer, wavefront: dl.wavefronts.Wavefront) -> dl.wavefronts.Wavefront:\n",
    "        \"\"\"\n",
    "        Applies the layer to the wavefront.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        wavefront : Wavefront\n",
    "            The wavefront to operate on.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        wavefront : Wavefront\n",
    "            The transformed wavefront.\n",
    "        \"\"\"\n",
    "        wavefront *= self.get_transmission()\n",
    "        if self.normalise:\n",
    "            wavefront = wavefront.normalise()\n",
    "        return wavefront\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simulate Spider -----------------------------------------------------------------#\n",
    "spider = dlu.spider(coords=coords, width=spider_width, angles=[spider_angle])\n",
    "transmission = dlu.combine([circle, spider]) \n",
    "# transmission *= intensity_dist # Scale transmission by true intensity distribution\n",
    "gauss_intensity_dist= gauss_2d(x_0=0, y_0=0, var_x=0.05, var_y=0.05, envelope=circle, pixel_coords=coords)\n",
    "\n",
    "# Zernike aberrations\n",
    "zernike_indicies = jnp.arange(4, 15) # up to 10th noll idxs (excluding piston)\n",
    "coeffs = jnp.zeros(zernike_indicies.shape)\n",
    "basis = dlu.zernike_basis(js=zernike_indicies, coordinates=coords, diameter=aperture_diameter)\n",
    "\n",
    "layers = [\n",
    "    # ('intensity_dist', dl.layers.TransmissiveLayer(transmission= gauss_intensity_dist)),\n",
    "    ('intensity_dist', GaussTransmissiveLayer(gaussian_param=np.array([0,0,0.05,0.05]), envelope=circle, pixel_coords= coords)),\n",
    "    ('aperture', dl.layers.BasisOptic(basis, transmission, coeffs, normalise=False)),\n",
    "]\n",
    "\n",
    "# Construct Optics\n",
    "optics = dl.AngularOpticalSystem(wf_npixels = wf_npixels, \n",
    "                                diameter=wf_diam, \n",
    "                                layers=layers, \n",
    "                                psf_npixels=psf_npix, \n",
    "                                psf_pixel_scale=psf_pixel_scale,\n",
    "                                oversample=oversample)\n",
    "\n",
    "# sim_psf = optics.propagate_mono(laser_wavelength)\n",
    "# opd = optics.aperture.eval_basis()\n",
    "\n",
    "# Using PointSources instead of single PointSource object to overcome float grad issue \n",
    "# https://github.com/LouisDesdoigts/dLux/issues/271 \n",
    "src = dl.PointSources(wavelengths=[laser_wavelength], flux =jnp.asarray([1e8],dtype=float))\n",
    "\n",
    "instrument = dl.Telescope(optics, ('source', src))\n",
    "sim_psf = instrument.model()\n",
    "\n",
    "# Show setup and transmission results\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(transmission)\n",
    "plt.colorbar()\n",
    "plt.title('Mask Transmission')\n",
    "plt.subplot(1,3,2)\n",
    "norm_psf = PowerNorm(0.5, vmax=sim_psf.max(), vmin=sim_psf.min())\n",
    "print(\"Total flux: {}\".format(sim_psf.sum()))\n",
    "plt.imshow(sim_psf, norm=norm_psf)\n",
    "plt.title('sqrt PSF (laser)')\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(optics.intensity_dist.transmission)\n",
    "plt.title('Intensity Distribution')\n",
    "plt.colorbar()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in spider images ⭐️\n",
    "- 03_laser_90deg_mean.png: Spider (90 deg oriented) setup with laser\n",
    "- 04_laser_90deg_mean.png: Same setup as above scenario, data taken ~1hr later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/spider/03_laser_90deg_mean.png\"\n",
    "data = imread(fname, as_gray=True) \n",
    "\n",
    "# Scale intensity\n",
    "data = data**1.2 # non-linear behaviour estimation\n",
    "current_range = data.max() - data.min()\n",
    "new_range = sim_psf.max() - sim_psf.min()\n",
    "scaled_data = ( (data - data.min()) * new_range )/current_range + sim_psf.min()\n",
    "# new_range = data.max() - 0\n",
    "# scaled_data = ( (data - data.min()) * new_range )/current_range + 0\n",
    "\n",
    "psf_center_idx = np.unravel_index(np.argmax(scaled_data, axis=None), scaled_data.shape)\n",
    "psf_hlf_sz = 20\n",
    "scaled_data = scaled_data[psf_center_idx[0]-psf_hlf_sz:psf_center_idx[0]+psf_hlf_sz,\n",
    "                            psf_center_idx[1]-psf_hlf_sz:psf_center_idx[1]+psf_hlf_sz]\n",
    "\n",
    "data = data[psf_center_idx[0]-psf_hlf_sz:psf_center_idx[0]+psf_hlf_sz,\n",
    "                            psf_center_idx[1]-psf_hlf_sz:psf_center_idx[1]+psf_hlf_sz]\n",
    "data = data + sim_psf.min() # ensure mu = 0 for k !=0 does not occur (logpmf shits itself)\n",
    "\n",
    "print(\"Total flux (Raw): {}\".format(data.sum()))\n",
    "print(\"Total flux (Scaled): {}\".format(scaled_data.sum()))\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(17,7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(scaled_data, norm=norm_psf)\n",
    "# plt.imshow(data**0.2)\n",
    "plt.colorbar()\n",
    "plt.title(\"Data (scaled)\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(sim_psf, norm=norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title(\"Simulated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @zdx.filter_jit\n",
    "# @zdx.filter_value_and_grad(param)\n",
    "# def loss_fn_mse(model, data, wavelength_center):\n",
    "\n",
    "#     simu_psf = model.propagate_mono(wavelength_center)\n",
    "\n",
    "#     mse = 1/simu_psf.size * ((data-simu_psf)**2).sum()\n",
    "\n",
    "#     return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    'aperture.coefficients',\n",
    "    'source.position',\n",
    "\n",
    "    #for gauss_2d params\n",
    "    'intensity_dist.gauss_param',\n",
    "    \n",
    "    # 'source.flux', # I don't think flux makes sense to fit as we have a limited number of non-zero pixels (need to retake data)\n",
    "    # 'intensity_dist.transmission',\n",
    "    ]\n",
    "@zdx.filter_jit\n",
    "@zdx.filter_value_and_grad(params)\n",
    "def loss_fn_gaussian(model, data):\n",
    "\n",
    "    simu_psf = model.model()\n",
    "\n",
    "    uncertainty = 0.1 # 10% err per pix TODO try increasing\n",
    "\n",
    "    loss = -jsp.stats.norm.logpdf(x=simu_psf, loc=data, scale=data*uncertainty).sum()\n",
    "\n",
    "    return loss\n",
    "@zdx.filter_jit\n",
    "@zdx.filter_value_and_grad(params)\n",
    "def loss_fn_poisson(model, data):\n",
    "\n",
    "    simu_psf = model.model()\n",
    "\n",
    "    loss = -jsp.stats.poisson.logpmf(k=simu_psf, mu=data).sum()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-8\n",
    "# optimisers = [\n",
    "#             optax.adam(optax.linear_schedule(init_value=learning_rate, end_value=0, transition_begin=500, transition_steps=1)),\n",
    "#             optax.adam(optax.linear_schedule(init_value=learning_rate, end_value=0, transition_begin=500, transition_steps=1)),\n",
    "#             # optax.adam(optax.piecewise_constant_schedule(init_value=1e-2*1e4, boundaries_and_scales={400: int(1e4)})),\n",
    "#             optax.sgd(optax.linear_schedule(init_value=0, end_value=1e-7, transition_begin=500, transition_steps=1)),\n",
    "#             # optax.adam(optax.linear_schedule(init_value=0, end_value=1e6, transition_begin=500, transition_steps=1)),\n",
    "#             # optax.adam(learning_rate=1e6),\n",
    "#             # optax.adam(learning_rate=1e-3),\n",
    "#               ]\n",
    "optimisers = [\n",
    "            optax.adam(learning_rate=learning_rate),\n",
    "            optax.adam(learning_rate=learning_rate),\n",
    "            # optax.adam(optax.piecewise_constant_schedule(init_value=1e-2*1e4, boundaries_and_scales={400: int(1e4)})),\n",
    "            optax.adam(learning_rate=1e-4),\n",
    "            # optax.adam(optax.linear_schedule(init_value=0, end_value=1e6, transition_begin=500, transition_steps=1)),\n",
    "            # optax.adam(learning_rate=1e6),\n",
    "            # optax.adam(learning_rate=1e-3),\n",
    "              ]\n",
    "\n",
    "\n",
    "# Optimise flux first\n",
    "optim, opt_state = zdx.get_optimiser(instrument, params, optimisers) # Needs to be iterable param (i.e. accessible via instrument class)\n",
    "\n",
    "progress_bar = tqdm(range(2000), desc='Loss: ')\n",
    "\n",
    "# Run optimisation loop \n",
    "net_losses, Coeffs, Positions, Fluxes, Dist_sum = [],[],[],[], []\n",
    "for i in progress_bar:\n",
    "    poiss_loss, poiss_grads = loss_fn_poisson(model = instrument, data = scaled_data)\n",
    "    # gauss_loss, gauss_grads = loss_fn_gaussian(model = instrument, data = data)\n",
    "    # poiss_grads = poiss_grads.set(\"source.flux\",gauss_grads.source.flux) # flux won't converge with poission (converges to Nan)\n",
    "\n",
    "    updates, opt_state = optim.update(poiss_grads, opt_state)\n",
    "    instrument = zdx.apply_updates(instrument, updates) \n",
    "    \n",
    "    # # Manual update for gauss transmissive \n",
    "    # # (updates are additive)\n",
    "    # prev_trans= instrument.intensity_dist.transmission\n",
    "    # new_trans = instrument.intensity_dist.get_transmission()\n",
    "    # instrument = instrument.set('intensity_dist.transmission', new_trans)\n",
    "\n",
    "\n",
    "    net_losses.append(poiss_loss)\n",
    "    Fluxes.append(instrument.source.flux)\n",
    "    Coeffs.append(instrument.aperture.coefficients)\n",
    "    Positions.append(instrument.source.position)\n",
    "    # Dist_sum.append((new_trans - prev_trans).sum())\n",
    "    Dist_sum.append(instrument.intensity_dist.gauss_param)\n",
    "    \n",
    "    progress_bar.set_postfix({'Loss': poiss_loss})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(np.array(net_losses))\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Training History\")\n",
    "ax.set_xlabel(\"Training Epoch\")\n",
    "ax.set_ylabel(\"Poisson Log-Likelihood\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 17)\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.subplot(1,4,1)\n",
    "plt.plot(np.asarray(Positions)[:,0,0], label=\"Position X\")\n",
    "plt.plot(np.asarray(Positions)[:,0,1], label=\"Position Y\")\n",
    "plt.title(\"Position\")\n",
    "plt.legend()\n",
    "plt.subplot(1,4,2)\n",
    "plt.plot(np.asarray(Dist_sum))\n",
    "plt.title(\"Intensity Distribution Sum of Diff\")\n",
    "plt.subplot(1,4,3)\n",
    "arr_coeffs = np.asarray(Coeffs)\n",
    "for i in range(len(Coeffs[0])):\n",
    "    label = \"Coeff \" + str(zernike_indicies[i])\n",
    "    plt.plot(arr_coeffs[:,i], label=label)\n",
    "plt.legend()\n",
    "plt.subplot(1,4,4)\n",
    "plt.plot(np.asarray(Fluxes))\n",
    "plt.title(\"Flux\")\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "norm_psf = PowerNorm(0.2, vmax=scaled_data.max(), vmin=scaled_data.min())\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(scaled_data, norm=norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title('Data')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "model_psf = instrument.model()\n",
    "current_range = model_psf.max() - model_psf.min()\n",
    "new_range = scaled_data.max() - scaled_data.min()\n",
    "model_psf = ( (model_psf - model_psf.min()) * new_range )/current_range + scaled_data.min()\n",
    "norm_psf = PowerNorm(0.2, vmax=model_psf.max(), vmin=model_psf.min())\n",
    "plt.imshow(model_psf, norm=norm_psf)\n",
    "plt.title('Model')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "resid = scaled_data - model_psf\n",
    "# resid = data - model_psf\n",
    "plt.imshow(resid, cmap='bwr', vmax = np.abs(resid).max(), vmin = -np.abs(resid).max())\n",
    "plt.colorbar()\n",
    "plt.title('Residuals')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "opd = instrument.aperture.eval_basis()\n",
    "plt.imshow(opd*transmission, cmap='viridis')\n",
    "plt.title('Retrieved Aberrations')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(instrument.intensity_dist.gauss_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(instrument.intensity_dist.get_transmission())\n",
    "# plt.imshow(instrument.intensity_dist.transmission)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(scaled_data, cmap='bone_r')\n",
    "ax[1].imshow(model_psf, cmap='bone_r')\n",
    "\n",
    "point = [20, 20]\n",
    "\n",
    "for i in [0, 1]:\n",
    "    ax[i].scatter(*point, marker='x', color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Found coefficients for noll idxs: {}\\n{}\".format(zernike_indicies, optics.aperture.coefficients))\n",
    "\n",
    "run1_coeffs = optics.aperture.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try with second data set... (1hr apart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialise model\n",
    "optics = dl.AngularOpticalSystem(wf_npixels = wf_npixels, \n",
    "                                diameter=wf_diam, \n",
    "                                layers=layers, \n",
    "                                psf_npixels=psf_npix, \n",
    "                                psf_pixel_scale=psf_pixel_scale,\n",
    "                                oversample=oversample)\n",
    "\n",
    "print(optics.aperture.coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/spider/04_laser_90deg_mean.png\"\n",
    "data = imread(fname, as_gray=True) \n",
    "\n",
    "# Scale intensity\n",
    "data = data**1.2 # non-linear behaviour estimation\n",
    "current_range = data.max() - data.min()\n",
    "new_range = sim_psf.max() - sim_psf.min()\n",
    "scaled_data = ( (data - data.min()) * new_range )/current_range + sim_psf.min()\n",
    "\n",
    "psf_center_idx = np.unravel_index(np.argmax(scaled_data, axis=None), scaled_data.shape)\n",
    "psf_hlf_sz = 50\n",
    "scaled_data = scaled_data[psf_center_idx[0]-psf_hlf_sz:psf_center_idx[0]+psf_hlf_sz,\n",
    "                            psf_center_idx[1]-psf_hlf_sz:psf_center_idx[1]+psf_hlf_sz]\n",
    "\n",
    "plt.figure(figsize=(17,7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(scaled_data, norm = norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title(\"Data\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(sim_psf, norm = norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title(\"Simulated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-10\n",
    "optim, opt_state = zdx.get_optimiser(optics, param, optax.adam(learning_rate)) \n",
    "\n",
    "progress_bar = tqdm(range(1000), desc='Loss: ')\n",
    "\n",
    "# Run optimisation loop \n",
    "net_losses, models = [], []\n",
    "for i in progress_bar:\n",
    "    loss, grads = loss_fn_poisson(model = optics, data = scaled_data, wavelength_center = laser_wavelength)\n",
    "    updates, opt_state = optim.update(grads, opt_state)\n",
    "    optics = zdx.apply_updates(optics, updates)\n",
    "\n",
    "    net_losses.append(loss)\n",
    "    models.append(optics)\n",
    "    \n",
    "    progress_bar.set_postfix({'Loss': loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(np.array(net_losses))\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Training History\")\n",
    "ax.set_xlabel(\"Training Epoch\")\n",
    "ax.set_ylabel(\"Poisson Log-Likelihood\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 17)\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "norm_psf = PowerNorm(0.5, vmax=scaled_data.max(), vmin=scaled_data.min())\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(scaled_data, norm=norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title('Data')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "model_psf = optics.propagate_mono(laser_wavelength)\n",
    "plt.imshow(model_psf, norm=norm_psf)\n",
    "plt.title('Model')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "resid = scaled_data - model_psf\n",
    "plt.imshow(resid, cmap='bwr', vmax = np.abs(resid).max(), vmin = -np.abs(resid).max())\n",
    "plt.colorbar()\n",
    "plt.title('Residuals')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "opd = optics.aperture.eval_basis()\n",
    "plt.imshow(opd*transmission)\n",
    "plt.title('Retrieved Aberrations')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Found coefficients for noll idxs: {}\\n{}\".format(zernike_indicies, optics.aperture.coefficients))\n",
    "\n",
    "run2_coeffs = optics.aperture.coefficients\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "x = np.arange(2,11)\n",
    "plt.plot(zernike_indicies,run1_coeffs, label='Run 1')\n",
    "plt.plot(zernike_indicies, run2_coeffs, label='Run 2')\n",
    "plt.xlabel('Noll Index')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.title(\"Phase Retrieval 1hr Apart\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try different orientation spider 🕷️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simulate Spider -----------------------------------------------------------------#\n",
    "spider = dlu.spider(coords=coords, width=spider_width, angles=[180]) #TODO try 0 deg for spider because loading in data flips along x-axis\n",
    "transmission = dlu.combine([circle, spider]) \n",
    "transmission *= intensity_dist\n",
    "\n",
    "# Zernike aberrations\n",
    "coeffs = np.zeros(zernike_indicies.shape)#run1_coeffs\n",
    "basis = dlu.zernike_basis(js=zernike_indicies, coordinates=coords, diameter=aperture_diameter)\n",
    "\n",
    "layers = [\n",
    "    ('aperture', dl.layers.BasisOptic(basis, transmission, coeffs, normalise=True))\n",
    "]\n",
    "\n",
    "# Construct Optics\n",
    "optics = dl.AngularOpticalSystem(wf_npixels = wf_npixels, \n",
    "                                diameter=wf_diam, \n",
    "                                layers=layers, \n",
    "                                psf_npixels=psf_npix, \n",
    "                                psf_pixel_scale=psf_pixel_scale,\n",
    "                                oversample=oversample)\n",
    "\n",
    "\n",
    "sim_psf = optics.propagate_mono(laser_wavelength)\n",
    "opd = optics.aperture.eval_basis()\n",
    "\n",
    "# Show setup and transmission results\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(transmission)\n",
    "plt.colorbar()\n",
    "plt.title('Transmission')\n",
    "plt.subplot(1,3,2)\n",
    "norm_psf = PowerNorm(0.5, vmax=sim_psf.max(), vmin=sim_psf.min())\n",
    "plt.imshow(sim_psf, norm=norm_psf)\n",
    "plt.title('sqrt PSF (laser)')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(opd)\n",
    "plt.title('Initialised Aberrations')\n",
    "plt.colorbar(label='OPD (m)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/spider/02_laser_180deg_mean.png\"\n",
    "data = imread(fname, as_gray=True) \n",
    "\n",
    "# Scale intensity\n",
    "data = data**1.2 # non-linear behaviour estimation\n",
    "current_range = data.max() - data.min()\n",
    "new_range = sim_psf.max() - sim_psf.min()\n",
    "scaled_data = ( (data - data.min()) * new_range )/current_range + sim_psf.min()\n",
    "\n",
    "psf_center_idx = np.unravel_index(np.argmax(scaled_data, axis=None), scaled_data.shape)\n",
    "psf_hlf_sz = 50\n",
    "scaled_data = scaled_data[psf_center_idx[0]-psf_hlf_sz:psf_center_idx[0]+psf_hlf_sz,\n",
    "                            psf_center_idx[1]-psf_hlf_sz:psf_center_idx[1]+psf_hlf_sz]\n",
    "\n",
    "plt.figure(figsize=(17,7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(scaled_data, norm = norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title(\"Data\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(sim_psf, norm = norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title(\"Simulated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-10\n",
    "optim, opt_state = zdx.get_optimiser(optics, param, optax.adam(learning_rate)) \n",
    "\n",
    "progress_bar = tqdm(range(1000), desc='Loss: ')\n",
    "\n",
    "# Run optimisation loop \n",
    "net_losses, models = [], []\n",
    "for i in progress_bar:\n",
    "    loss, grads = loss_fn_poisson(model = optics, data = scaled_data, wavelength_center = laser_wavelength)\n",
    "    updates, opt_state = optim.update(grads, opt_state)\n",
    "    optics = zdx.apply_updates(optics, updates)\n",
    "\n",
    "    net_losses.append(loss)\n",
    "    models.append(optics)\n",
    "    \n",
    "    progress_bar.set_postfix({'Loss': loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(np.array(net_losses))\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Training History\")\n",
    "ax.set_xlabel(\"Training Epoch\")\n",
    "ax.set_ylabel(\"Poisson Log-Likelihood\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 17)\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "norm_psf = PowerNorm(0.5, vmax=scaled_data.max(), vmin=scaled_data.min())\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(scaled_data, norm=norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title('Data')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "model_psf = optics.propagate_mono(laser_wavelength)\n",
    "plt.imshow(model_psf, norm=norm_psf)\n",
    "plt.title('Model')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "resid = scaled_data - model_psf\n",
    "plt.imshow(resid, cmap='bwr', vmax = np.abs(resid).max(), vmin = -np.abs(resid).max())\n",
    "plt.colorbar()\n",
    "plt.title('Residuals')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "opd = optics.aperture.eval_basis()\n",
    "plt.imshow(opd*transmission)\n",
    "plt.title('Retrieved Aberrations')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run3_coeffs = optics.aperture.coefficients\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "x = np.arange(2,11)\n",
    "plt.plot(zernike_indicies,run1_coeffs, label='Run 1')\n",
    "plt.plot(zernike_indicies, run2_coeffs, label='Run 2')\n",
    "plt.plot(zernike_indicies, run3_coeffs, label='Run 3')\n",
    "plt.xlabel('Noll Index')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.title(\"Phase Retrieval 1hr Apart\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try ✨Phase Diversity (sort of)✨ Using two different Spider Orientations ☀️\n",
    "- Phase Diversity involves taking a second image with a known aberration applied. We have just taken a second image\n",
    "with a different known spider orientation, but we can optimise using both scenarios simultaneously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions (jit-compiled)\n",
    "param = 'aperture.coefficients'\n",
    "\n",
    "# Poisson log-likelihood\n",
    "@zdx.filter_jit\n",
    "@zdx.filter_value_and_grad(param)\n",
    "def loss_fn_poisson(model_one, model_two_psf, data_one, data_two, wavelength_center):\n",
    "    \"\"\"\n",
    "        Poisson log-likelihood loss function calculated over multiple psfs. \n",
    "\n",
    "        jsp.stats.poisson.logpmf returns the log of the Probability Mass Function (PMF)\n",
    "        for a poisson distribution. By maximum likelihood estimation, we can optimise \n",
    "        the system by minimising the negative log-likelihood, i.e. the negative of the\n",
    "        output from jsp.stats.poisson.logpmf (summed over)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : dLux model\n",
    "            dLux model to propagate the wavefront\n",
    "        data : Array\n",
    "            Array of data\n",
    "        wavelength_center : float   \n",
    "    \"\"\"\n",
    "    simu_psf_one = model_one.propagate_mono(wavelength_center)\n",
    " \n",
    "    net_loss = -(jsp.stats.poisson.logpmf(k = simu_psf_one, mu = data_one).sum() + jsp.stats.poisson.logpmf(k = model_two_psf, mu = data_two).sum())\n",
    "\n",
    "    return net_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simulate Spider -----------------------------------------------------------------#\n",
    "circle = dlu.circle(coords=coords, radius=aperture_diameter/2) \n",
    "spider = dlu.spider(coords=coords, width=spider_width, angles=[180]) \n",
    "transmission = dlu.combine([circle, spider]) \n",
    "transmission *= intensity_dist\n",
    "\n",
    "# Zernike aberrations\n",
    "coeffs = np.zeros(zernike_indicies.shape)\n",
    "basis = dlu.zernike_basis(js=zernike_indicies, coordinates=coords, diameter=aperture_diameter)\n",
    "\n",
    "layers = [\n",
    "    ('aperture', dl.layers.BasisOptic(basis, transmission, coeffs, normalise=True))\n",
    "]\n",
    "\n",
    "# Construct Optics\n",
    "model_one = dl.AngularOpticalSystem(wf_npixels = wf_npixels, \n",
    "                                diameter=wf_diam, \n",
    "                                layers=layers, \n",
    "                                psf_npixels=psf_npix, \n",
    "                                psf_pixel_scale=psf_pixel_scale,\n",
    "                                oversample=oversample)\n",
    "\n",
    "sim_psf = model_one.propagate_mono(laser_wavelength)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(transmission)\n",
    "plt.colorbar()\n",
    "plt.title('Model 1 Transmission')\n",
    "plt.subplot(2,2,2)\n",
    "norm_psf = PowerNorm(0.5, vmax=sim_psf.max(), vmin=sim_psf.min())\n",
    "plt.imshow(sim_psf, norm=norm_psf)\n",
    "plt.title('Model 1 sqrt PSF (laser)')\n",
    "plt.colorbar()\n",
    "\n",
    "spider = dlu.spider(coords=coords, width=spider_width, angles=[270]) \n",
    "transmission = dlu.combine([circle, spider]) \n",
    "transmission *= intensity_dist\n",
    "layers = [\n",
    "    ('aperture', dl.layers.BasisOptic(basis, transmission, coeffs, normalise=True))\n",
    "]\n",
    "\n",
    "model_two = dl.AngularOpticalSystem(wf_npixels = wf_npixels, \n",
    "                                diameter=wf_diam, \n",
    "                                layers=layers, \n",
    "                                psf_npixels=psf_npix, \n",
    "                                psf_pixel_scale=psf_pixel_scale,\n",
    "                                oversample=oversample)\n",
    "\n",
    "sim_psf = model_two.propagate_mono(laser_wavelength)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(transmission)\n",
    "plt.colorbar()\n",
    "plt.title('Model 2 Transmission')\n",
    "plt.subplot(2,2,4)\n",
    "norm_psf = PowerNorm(0.5, vmax=sim_psf.max(), vmin=sim_psf.min())\n",
    "plt.imshow(sim_psf, norm=norm_psf)\n",
    "plt.title('Model 2 sqrt PSF (laser)')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PSFS = []\n",
    "fnames = [\"data/spider/02_laser_180deg_mean.png\", \"data/spider/04_laser_90deg_mean.png\"]\n",
    "for i in range(len(fnames)):\n",
    "    fname = fnames[i]\n",
    "    data = imread(fname, as_gray=True) \n",
    "\n",
    "    # Scale intensity\n",
    "    data = data**1.2 # non-linear behaviour estimation\n",
    "    current_range = data.max() - data.min()\n",
    "    new_range = sim_psf.max() - sim_psf.min()\n",
    "    scaled_data = ( (data - data.min()) * new_range )/current_range + sim_psf.min()\n",
    "\n",
    "    psf_center_idx = np.unravel_index(np.argmax(scaled_data, axis=None), scaled_data.shape)\n",
    "    psf_hlf_sz = 50\n",
    "    scaled_data = scaled_data[psf_center_idx[0]-psf_hlf_sz:psf_center_idx[0]+psf_hlf_sz,\n",
    "                                psf_center_idx[1]-psf_hlf_sz:psf_center_idx[1]+psf_hlf_sz]\n",
    "    \n",
    "    DATA_PSFS.append(scaled_data)  \n",
    "\n",
    "plt.figure(figsize=(17,7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(DATA_PSFS[0], norm = norm_psf)\n",
    "plt.title(\"Data One\")\n",
    "plt.colorbar()\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(DATA_PSFS[1], norm = norm_psf)\n",
    "plt.title(\"Data Two\")\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-11\n",
    "\n",
    "optim, opt_state = zdx.get_optimiser(model_one, param, optax.adam(learning_rate)) \n",
    "progress_bar = tqdm(range(500), desc='Loss: ')\n",
    "\n",
    "# Run optimisation loop \n",
    "net_losses = []\n",
    "for i in progress_bar:\n",
    "    model_two_psf = model_two.propagate_mono(laser_wavelength)\n",
    "    loss, grads = loss_fn_poisson(model_one = model_one, # grads calculated on model one coeffs but loss on both \n",
    "                                  model_two_psf=model_two_psf, \n",
    "                                  data_one = DATA_PSFS[0], \n",
    "                                  data_two = DATA_PSFS[1],\n",
    "                                  wavelength_center = laser_wavelength)\n",
    "    \n",
    "    # Update model one\n",
    "    updates, opt_state = optim.update(grads, opt_state)\n",
    "    model_one = zdx.apply_updates(model_one, updates)\n",
    "\n",
    "    # Update model two\n",
    "    model_two = zdx.apply_updates(model_two, updates)\n",
    "\n",
    "    net_losses.append(loss)\n",
    "    \n",
    "    progress_bar.set_postfix({'Loss': loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(np.array(net_losses))\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Training History\")\n",
    "ax.set_xlabel(\"Training Epoch\")\n",
    "ax.set_ylabel(\"Poisson Log-Likelihood\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 17)\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "models = [model_one, model_two]\n",
    "for i, data in enumerate(DATA_PSFS):\n",
    "    plt.figure(figsize=(12,10))\n",
    "    norm_psf = PowerNorm(0.5, vmax=data.max(), vmin=data.min())\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.imshow(data, norm=norm_psf)\n",
    "    plt.colorbar()\n",
    "    plt.title('Data')\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    model_psf = models[i].propagate_mono(laser_wavelength)\n",
    "    plt.imshow(model_psf, norm=norm_psf)\n",
    "    plt.title('Model')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(2,2,3)\n",
    "    resid = data - model_psf\n",
    "    plt.imshow(resid, cmap='bwr', vmax = np.abs(resid).max(), vmin = -np.abs(resid).max())\n",
    "    plt.colorbar()\n",
    "    plt.title('Residuals')\n",
    "\n",
    "    plt.subplot(2,2,4)\n",
    "    opd = models[i].aperture.eval_basis()\n",
    "    plt.imshow(opd*models[i].aperture.transmission)\n",
    "    plt.title('Retrieved Aberrations')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toliman_dp_design",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
