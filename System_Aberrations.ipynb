{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOLIMAN Pupil Gluing Analysis: Preliminary Measurements\n",
    "\n",
    "**Aim:**  \n",
    "To determine:\n",
    "1. The optical aberrations induced by the lab setup for pupil testing (consisting of 2 OAPs)\n",
    "2. The intensity distribution ouput from the optical fiber output for later modelling\n",
    "\n",
    "If we can show these aberrations are static over a long enough period of time (> 30min) then we can confidently remove them from the phase retrieval analysis of the later measurements (glued vs non-glued).\n",
    "\n",
    "We have chosen to place a spider mask (necessary asymmetry) within the collimated beam to characterise these aberrations via phase retrieval (thank u differentiable modelling/dLux 💖)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dLux as dl\n",
    "import dLux.utils as dlu\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import jax.random as jr\n",
    "import jax.scipy as jsp\n",
    "from jax import vmap  \n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "jax.config.update(\"jax_debug_nans\", False)\n",
    "jax.config.update('jax_disable_jit', False)\n",
    "\n",
    "import zodiax as zdx\n",
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.filters import window\n",
    "import skimage as ski\n",
    "from skimage.transform import resize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import PowerNorm\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"image.origin\"] = 'lower'\n",
    "plt.rcParams['figure.dpi'] = 72\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "plt.rcParams[\"axes.titlesize\"] = 18\n",
    "plt.rcParams[\"figure.titlesize\"] = 18\n",
    "plt.rcParams[\"axes.labelsize\"] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Physical Parameters ---------------------------------------------------------------------#\n",
    "aperture_npix = 512           # Number of pixels across the aperture\n",
    "aperture_diameter = 126e-3    # (m)\n",
    "spider_width = 20e-3          # Spider width (m)\n",
    "spider_angle =270             # Spider angle (degrees), clockwise, 0 is spider pointing vertically up\n",
    "coords = dlu.pixel_coords(npixels=aperture_npix, diameter=aperture_diameter)\n",
    "circle = dlu.circle(coords=coords, radius=aperture_diameter/2) \n",
    "\n",
    "# Observations wavelengths (bandpass of 530-640nm)\n",
    "wavelengths = np.linspace(530e-9, 640e-9, 100)  # Wavelengths to simulate (m)\n",
    "laser_wavelength =  635e-09  # for laser data\n",
    "wf_npixels = aperture_npix  # Number of pixels across the wavefront\n",
    "wf_diam = aperture_diameter             # Diameter of initial wavefront to propagate wavefront (m)\n",
    "\n",
    "# Dtector parameters (BFS-U3-200S6-BD)\n",
    "BFS_px_sep = 2.4e-6 *1e3        # pixel separation (mm)\n",
    "f_det = 1300#1350                    # Focal length from OAP2 to detector (mm) \n",
    "px_ang_sep = 2*np.arctan( (BFS_px_sep/2)/f_det ) # angular sep between pixels (rad)\n",
    "\n",
    "# Simulated Detector\n",
    "psf_npix = 28                 # Number of pixels along one dim of the PSF\n",
    "oversample = 1                 # Oversampling factor for the PSF\n",
    "psf_pixel_scale = dlu.rad2arcsec(px_ang_sep) # arcsec (to match detector plate scale) 80e-4 \n",
    "\n",
    "run_coeffs, run_poses, run_fluxes = [],[],[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in some ✨real✨ data 🌈\n",
    "- Check intensity distribution across pupil first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/intensity/15_07_intensity_dist.png\"\n",
    "data = imread(fname, as_gray=True) \n",
    "manual_lim = [1363,4203,386,3214]\n",
    "data = data[manual_lim[2]:manual_lim[3], manual_lim[0]:manual_lim[1]]\n",
    "data = (data - data.min())/(data.max()-data.min())\n",
    "\n",
    "blurred = ski.filters.gaussian(data, sigma=(120, 120))\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(data)\n",
    "plt.title(\"Data - pre-focus\")\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(blurred)\n",
    "plt.title(\"Data blurred\")\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,3)\n",
    "intensity_dist = resize(blurred, (aperture_npix, aperture_npix))\n",
    "intensity_dist = (intensity_dist - intensity_dist.min())/(intensity_dist.max()-intensity_dist.min()) # re-map from 0-1\n",
    "# intensity_dist = np.fliplr(intensity_dist)\n",
    "plt.title(\"Blurred re-sized\")\n",
    "plt.imshow(intensity_dist)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 2D gaussian to approximate this\n",
    "def gauss_2d(x_0, y_0, var_x, var_y, pixel_coords):\n",
    "    \"\"\"\n",
    "        Output 2D gaussian array with amplitude of 1, within\n",
    "        aperture profile.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        x_0, y_0 : float\n",
    "            (x,y) coordinate of the center of the gaussian (m)\n",
    "        var_x, var_y : float\n",
    "            Variance in the x and y directions (m)\n",
    "        pixel_coords : ndarray\n",
    "            3D array of pixel coordinates over which gaussian is defined in the shape\n",
    "            (2, npix, npix) where npix is the number of pixels across one dimension of the\n",
    "            each 2D array (one for X and Y).\n",
    "    \"\"\"\n",
    "    X, Y = pixel_coords\n",
    "\n",
    "    z = jnp.exp(-(X - x_0)**2/(2*var_x**2) - (Y - y_0)**2/(2*var_y**2))\n",
    "\n",
    "    return z\n",
    "\n",
    "var = 10e-2\n",
    "wf_pixel_coords = dlu.pixel_coords(npixels=psf_npix, diameter=wf_diam)\n",
    "test = gauss_2d(x_0=0, y_0=0, var_x=var, var_y=var, pixel_coords=wf_pixel_coords)\n",
    "plt.imshow(test)\n",
    "plt.title(\"Approximated WF intensity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dLux class for this gauss transmissive layer\n",
    "# maybe modelling a source object would be easier?\n",
    "class GaussTransmissiveLayer(dl.layers.optical_layers.TransmissiveLayer):\n",
    "    \"\"\"\n",
    "        Inherits from dl.layers.TransmissiveLayer and allows for\n",
    "        a Gaussian transmissive layer to be simulated. Useful for \n",
    "        simulating a wavefront that is not uniform in intensity.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        transmission: Array\n",
    "            The Array of transmission values to be applied to the input wavefront.\n",
    "        gaussian_param: Array = [var_x, var_y], shape (2,)\n",
    "            The parameters defining the 2D Gaussian to be applied to the input wavefront.\n",
    "            Where:\n",
    "            var_x, var_y = float\n",
    "                Variance in the x and y directions (m)\n",
    "            Center of Gaussian is given by position of Pointsource\n",
    "        pixel_coords : Array\n",
    "            3D array of pixel coordinates over which gaussian is defined in the shape\n",
    "            (2, npix, npix) where npix is the number of pixels across one dimension of the\n",
    "            each 2D array (one for X and Y).\n",
    "        det_npix: int\n",
    "            Number of pixels across the detector.\n",
    "        psf_pixel_scale: float\n",
    "            Pixel scale of the detector (arcsec/px).\n",
    "        normalise: bool\n",
    "            Whether to normalise the wavefront after passing through the optic.\n",
    "    \"\"\"\n",
    "    X: jnp.array\n",
    "    Y: jnp.array\n",
    "\n",
    "    gauss_param: jnp.array\n",
    "    point_source: dl.PointSources\n",
    "    det_npix: int\n",
    "    pp_npix: int # pupil-plane pixel size\n",
    "    psf_pixel_scale: float\n",
    "    pixel_size: float\n",
    "\n",
    "    def __init__(\n",
    "        self: dl.layers.optical_layers.OpticalLayer,\n",
    "        point_source: dl.PointSources,\n",
    "        gaussian_param: jnp.array,\n",
    "        pixel_coords: jnp.array,\n",
    "        det_npix: int,\n",
    "        psf_pixel_scale: float,\n",
    "        normalise: bool = False,\n",
    "    ):\n",
    "        self.X, self.Y = pixel_coords\n",
    "        assert gaussian_param.shape == (2,), \"Gaussian parameters must be of shape (2,) in form [var_x, var_y] \"\n",
    "        self.pp_npix = self.X.shape[0]\n",
    "        self.gauss_param = gaussian_param\n",
    "        self.point_source = point_source\n",
    "\n",
    "        self.det_npix = det_npix\n",
    "        self.psf_pixel_scale = psf_pixel_scale\n",
    "        self.pixel_size = jnp.abs(pixel_coords[0,0,1] - pixel_coords[0,0,0]) #distance between adjacent px\n",
    "\n",
    "        trans = self.get_transmission()\n",
    "\n",
    "        super().__init__(transmission=trans, normalise=normalise)\n",
    "\n",
    "    def get_transmission(self):\n",
    "        # angular position to number of pixels across detector\n",
    "        pos = self.point_source.position[0]\n",
    "        x_0_px = dlu.rad2arcsec(pos[0]) / self.psf_pixel_scale \n",
    "        y_0_px = dlu.rad2arcsec(pos[1]) / self.psf_pixel_scale \n",
    "\n",
    "        # convert to number of pixels across pupil plane\n",
    "        x_0_px *= self.pp_npix / self.det_npix\n",
    "        y_0_px *= self.pp_npix / self.det_npix \n",
    "\n",
    "        # convert to linear distance (m) across pupil plane\n",
    "        x_0 = x_0_px*self.pixel_size\n",
    "        y_0 = y_0_px*self.pixel_size\n",
    "\n",
    "        # x_0 *= -1 #dLux conventions or Positon\n",
    "        # y_0 *= -1\n",
    "\n",
    "        z = jnp.exp(-(self.X - x_0)**2/(2*self.gauss_param[0]**2) - (self.Y - y_0)**2/(2*self.gauss_param[1]**2))\n",
    "\n",
    "        return z \n",
    "\n",
    "    def apply(self: dl.layers.optical_layers.OpticalLayer, wavefront: dl.wavefronts.Wavefront) -> dl.wavefronts.Wavefront:\n",
    "        \"\"\"\n",
    "        Applies the layer to the wavefront.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        wavefront : Wavefront\n",
    "            The wavefront to operate on.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        wavefront : Wavefront\n",
    "            The transformed wavefront.\n",
    "        \"\"\"\n",
    "        wavefront *= self.get_transmission()\n",
    "        if self.normalise:\n",
    "            wavefront = wavefront.normalise()\n",
    "        return wavefront\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create source class that inherits from dLux ResolvedSource class\n",
    "# from jax.scipy.signal import convolve\n",
    "\n",
    "# class GaussResolvedSource(dl.sources.ResolvedSource):\n",
    "#     \"\"\"\n",
    "#         Inherits from dLux ResolvedSource class and allows for modelling\n",
    "#         of a object with a Gaussian intensity profile. Useful for modelling\n",
    "#         fiber optical source.\n",
    "\n",
    "#         Attributes\n",
    "#         ----------\n",
    "#         position : Array, radians\n",
    "#             The (x, y) on-sky position of this object.\n",
    "#         flux : float, photons\n",
    "#             The flux of the object.\n",
    "#         distribution : Array\n",
    "#             The array of intensities representing the resolved source.\n",
    "#         spectrum : Spectrum\n",
    "#             The spectrum of this object, represented by a Spectrum object.\n",
    "#         gaussian_param: Array = [x_0, y_0, var_x, var_y], shape (4,)\n",
    "#             The parameters defining the 2D Gaussian to be applied to the input wavefront.\n",
    "#             Where:\n",
    "#             x_0, y_0 = float\n",
    "#                 (x,y) coordinate of the center of the gaussian (m)\n",
    "#             var_x, var_y = float\n",
    "#                 Variance in the x and y directions (m)\n",
    "#         pixel_coords : Array\n",
    "#             3D array of pixel coordinates describing the wavefront from the source.\n",
    "#             Shape (2, npix, npix) where npix is the number of pixels across one \n",
    "#             dimension of the square wavefront (two 2D arrays, one for X coords and\n",
    "#             the other for Y coords).\n",
    "#     \"\"\"\n",
    "#     X: jnp.array\n",
    "#     Y: jnp.array\n",
    "\n",
    "#     gauss_param: jnp.array\n",
    "#     def __init__(\n",
    "#         self: dl.sources.Source,\n",
    "#         gaussian_param: jnp.array,\n",
    "#         pixel_coords: jnp.array,\n",
    "#         wavelengths: jnp.array = None,\n",
    "#         position: jnp.array = np.zeros(2),\n",
    "#         flux: float = 1.0,\n",
    "#         distribution: jnp.array = np.ones((3, 3)),\n",
    "#         weights: jnp.array = None,\n",
    "#         spectrum: dl.spectra.Spectrum = None,\n",
    "#     ):\n",
    "\n",
    "#         self.X, self.Y = pixel_coords\n",
    "#         assert gaussian_param.shape == (4,), \"Gaussian parameters must be of shape (4,) in form [x_0, y_0, var_x, var_y] \"\n",
    "#         self.gauss_param = gaussian_param\n",
    "\n",
    "#         self.position = position\n",
    "#         self.distribution = jnp.exp(-(self.X - self.position[0])**2/(2*self.gauss_param[2]**2) - (self.Y - self.position[1])**2/(2*self.gauss_param[3]**2))\n",
    "        \n",
    "#         super().__init__(\n",
    "#             wavelengths=wavelengths,\n",
    "#             position=position,\n",
    "#             flux=flux,\n",
    "#             distribution=self.distribution,\n",
    "#             weights=weights,\n",
    "#             spectrum=spectrum,\n",
    "#         )\n",
    "    \n",
    "#     def get_distribution(self):\n",
    "#         \"\"\"\n",
    "#             For every time gauss params are updated\n",
    "#         \"\"\"\n",
    "#         # z = jnp.exp(-(self.X - self.gauss_param[0])**2/(2*self.gauss_param[2]**2) - (self.Y - self.gauss_param[1])**2/(2*self.gauss_param[3]**2))\n",
    "#         z = jnp.exp(-(self.X - self.position[0])**2/(2*self.gauss_param[2]**2) - (self.Y - self.position[1])**2/(2*self.gauss_param[3]**2))\n",
    "\n",
    "#         return z\n",
    "\n",
    "#     def normalise(self: dl.sources.Source) -> dl.sources.Source:\n",
    "#         \"\"\"\n",
    "#         Method for returning a new source object with a normalised total\n",
    "#         spectrum and source distribution.\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         source : Source\n",
    "#             The source object with the normalised spectrum and distribution.\n",
    "#         \"\"\"\n",
    "#         spectrum = self.spectrum.normalise()\n",
    "#         distribution_floor = jnp.maximum(self.get_distribution(), 0.0)\n",
    "#         distribution = distribution_floor / distribution_floor.sum()\n",
    "#         return self.set([\"spectrum\", \"distribution\"], [spectrum, distribution])\n",
    "\n",
    "#     def model(\n",
    "#         self: dl.sources.Source,\n",
    "#         optics: dl.optical_systems.BaseOpticalSystem = None,\n",
    "#         return_wf : bool = False,\n",
    "#         return_psf : bool = False\n",
    "#     ) -> jnp.array:\n",
    "#         \"\"\"\n",
    "#         Models the source object through the provided optics.\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         optics : Optics\n",
    "#             The optics through which to model the source object.\n",
    "#         return_wf : bool = False\n",
    "#             Should the Wavefront object be returned instead of the psf Array?\n",
    "#         return_psf : bool = False\n",
    "#             Should the PSF object be returned instead of the psf Array?\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         object : Array\n",
    "#             psf array\n",
    "#         \"\"\"\n",
    "#         if return_wf and return_psf:\n",
    "#             raise ValueError(\n",
    "#                 \"return_wf and return_psf cannot both be True. \"\n",
    "#                 \"Please choose one.\"\n",
    "#             )\n",
    "        \n",
    "#         # Normalise and get parameters\n",
    "#         self = self.normalise()\n",
    "#         weights = self.weights * self.flux\n",
    "\n",
    "\n",
    "#         # Note we always return wf here so we can convolve each wavelength\n",
    "#         # individually if a chromatic wavefront output is required.\n",
    "#         wf = optics.propagate(\n",
    "#             self.wavelengths, self.position, weights, return_wf=True\n",
    "#         )\n",
    "\n",
    "#         # Returning wf is a special case\n",
    "#         if return_wf:\n",
    "#             conv_fn = lambda psf: convolve(psf, self.get_distribution(), mode=\"same\")\n",
    "#             return wf.set(\"amplitude\", vmap(conv_fn)(wf.psf) ** 0.5)\n",
    "\n",
    "#         # Return psf object\n",
    "#         conv_psf = convolve(wf.psf.sum(0), self.get_distribution(), mode=\"same\")\n",
    "#         if return_psf:\n",
    "#             return dl.psfs.PSF(conv_psf, wf.pixel_scale.mean())\n",
    "\n",
    "#         # Return array psf\n",
    "#         return conv_psf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussResolvedSource(dl.sources.PointSources):\n",
    "    \"\"\"\n",
    "        Inherits from dLux PointSources class and allows for modelling\n",
    "        of an object with a Gaussian intensity profile. Useful for modelling\n",
    "        fiber optical source. Using PointSources instead of PointSource so that\n",
    "        flux is casted as an array and can be optimised. \n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        position : Array, radians\n",
    "            The (x, y) on-sky position of this object.\n",
    "        flux : float, photons\n",
    "            The flux of the object.\n",
    "        spectrum : Spectrum\n",
    "            The spectrum of this object, represented by a Spectrum object.\n",
    "        gaussian_param: Array = [var_x, var_y], shape (2,)\n",
    "            The parameters defining the 2D Gaussian to be applied to the input wavefront.\n",
    "            Where:\n",
    "            var_x, var_y = float\n",
    "                Variance in the x and y directions (m)\n",
    "            The x_0 and y_0 position of the gaussian is set to the position of the source.\n",
    "        pixel_coords : Array\n",
    "            3D array of pixel coordinates describing the wavefront from the source.\n",
    "            Shape (2, npix, npix) where npix is the number of pixels across one \n",
    "            dimension of the square wavefront (two 2D arrays, one for X coords and\n",
    "            the other for Y coords).\n",
    "    \"\"\"\n",
    "    X: jnp.array\n",
    "    Y: jnp.array\n",
    "\n",
    "    gauss_param: jnp.array\n",
    "    pixel_size: float\n",
    "\n",
    "    def __init__(\n",
    "        self: dl.sources.Source,\n",
    "        gaussian_param: jnp.array,\n",
    "        pixel_coords: jnp.array,\n",
    "        wavelengths: jnp.array = None,\n",
    "        position: jnp.array = np.zeros((1,2)),\n",
    "        # flux: float = 1.0,\n",
    "        flux: jnp.array = None,\n",
    "        weights: jnp.array = None,\n",
    "        spectrum: dl.spectra.Spectrum = None,\n",
    "    ):\n",
    "\n",
    "        self.X, self.Y = pixel_coords\n",
    "        assert gaussian_param.shape == (2,), \"Gaussian parameters must be of shape (2,) in form [var_x, var_y] \"\n",
    "        self.gauss_param = gaussian_param\n",
    "        self.pixel_size = jnp.abs(pixel_coords[0,0,1] - pixel_coords[0,0,0]) #distance between adjacent px\n",
    "\n",
    "        # More complex parameter checks here because of extra dims\n",
    "        self.position = np.asarray(position, dtype=float)\n",
    "        if self.position.ndim != 2:\n",
    "            raise ValueError(\"position must be a 2d array.\")\n",
    "\n",
    "        if flux is None:\n",
    "            self.flux = np.ones(len(self.position))\n",
    "        else:\n",
    "            self.flux = np.asarray(flux, dtype=float)\n",
    "\n",
    "            if self.flux.ndim != 1:\n",
    "                raise ValueError(\"flux must be a 1d array.\")\n",
    "\n",
    "            if len(self.flux) != len(self.position):\n",
    "                raise ValueError(\n",
    "                    \"Length of flux must be equal to length of \" \"positions.\"\n",
    "                )\n",
    "        \n",
    "        super().__init__(\n",
    "            wavelengths=wavelengths,\n",
    "            position=position,\n",
    "            flux=flux,\n",
    "            weights=weights,\n",
    "            spectrum=spectrum,\n",
    "        )\n",
    "    \n",
    "    def get_intensity_distribution(self, psf_pixel_scale: float = 1.0):\n",
    "        \"\"\"\n",
    "            For every time gauss params are updated\n",
    "            Gaussian with ampltidue of 1.\n",
    "        \"\"\"\n",
    "        # angular position to linear units across detector\n",
    "        pos = self.position[0]\n",
    "        x_0 = dlu.rad2arcsec(pos[0]) / psf_pixel_scale * self.pixel_size\n",
    "        y_0 = dlu.rad2arcsec(pos[1]) / psf_pixel_scale * self.pixel_size\n",
    "\n",
    "        x_0 *= -1 #dLux conventions\n",
    "        y_0 *= -1\n",
    "\n",
    "        # z = jnp.exp(-(self.X - self.position[0])**2/(2*self.gauss_param[0]**2) - (self.Y - self.position[1])**2/(2*self.gauss_param[1]**2))\n",
    "        z = jnp.exp(-(self.X - x_0)**2/(2*self.gauss_param[0]**2) - (self.Y - y_0)**2/(2*self.gauss_param[1]**2))\n",
    "\n",
    "\n",
    "        return z\n",
    "    \n",
    "    def model(\n",
    "        self: dl.sources.Source,\n",
    "        optics: dl.optical_systems.BaseOpticalSystem = None,\n",
    "        return_wf : bool = False,\n",
    "        return_psf : bool = False\n",
    "    ) -> jnp.array:\n",
    "        \"\"\"\n",
    "        Models the source object through the provided optics.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        optics : Optics\n",
    "            The optics through which to model the source object.\n",
    "        return_wf : bool = False\n",
    "            Should the Wavefront object be returned instead of the psf Array?\n",
    "        return_psf : bool = False\n",
    "            Should the PSF object be returned instead of the psf Array?\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        object : Array, Wavefront, PSF\n",
    "            if `return_wf` is False and `return_psf` is False, returns the psf Array.\n",
    "            if `return_wf` is True and `return_psf` is False, returns the Wavefront\n",
    "                object.\n",
    "            if `return_wf` is False and `return_psf` is True, returns the PSF object.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Normalise and get parameters\n",
    "        self = self.normalise()\n",
    "        weights = self.weights * self.flux\n",
    "        \n",
    "        # Note we always return wf here so we can ampltiude adjust each wavelength\n",
    "        # we multiply by sqrt(weight) to account for the fact that the PSF is the \n",
    "        # square of the amplitude\n",
    "        wf = optics.propagate(\n",
    "            self.wavelengths, self.position[0], weights, return_wf=True\n",
    "        )\n",
    "\n",
    "        wf = wf.multiply(\"amplitude\", self.get_intensity_distribution(optics.psf_pixel_scale)** 0.5)\n",
    "\n",
    "        # Returning wf is a special case\n",
    "        if return_wf:\n",
    "            return wf\n",
    "\n",
    "        # Return psf object\n",
    "        if return_psf:\n",
    "            return dl.psfs.PSF(wf.psf.sum(0), wf.pixel_scale.mean())\n",
    "\n",
    "        # Return array psf\n",
    "        return wf.psf.sum(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define non-linear detector response\n",
    "class ApplyBFSPixelResponse(dl.layers.detector_layers.DetectorLayer):\n",
    "    \"\"\"\n",
    "    Applies a pixel response array to the input psf, via a multiplication. This can be\n",
    "    used to model variations in the inter and intra-pixel sensitivity variations common\n",
    "    to most detectors.\n",
    "\n",
    "    We have characterised the BFS detector to have a gamma curve gain response per px.\n",
    "\n",
    "    ??? abstract \"UML\"\n",
    "        ![UML](../../assets/uml/ApplyPixelResponse.png)\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    pixel_response : Array\n",
    "        The pixel_response to apply to the input psf in the form of gamma fn coeffs:\n",
    "        measured_intensity = alpha + beta*real_intensity^gamma\n",
    "        with    pixel_response[0] = alpha\n",
    "                pixel_response[1] = beta\n",
    "                pixel_response[2] = gamma\n",
    "    luminance_min, luminance_max : float\n",
    "        The minimum and maximum input luminance values for the pixel response (with which the \n",
    "        gamma curve was characterised).\n",
    "    intensity_min, intensity_max : float\n",
    "        The minimum and maximum output intensity values for the pixel response (with which the \n",
    "        gamma curve was characterised).\n",
    "    \"\"\"\n",
    "\n",
    "    pixel_response: jnp.array\n",
    "    x_intercepts: jnp.array\n",
    "    # luminance_min: float\n",
    "    # luminance_max: float\n",
    "    # intensity_min: float\n",
    "    # intensity_max: jnp.float64\n",
    "\n",
    "    def __init__(self: dl.layers.detector_layers.DetectorLayer, \n",
    "                 pixel_response: jnp.array,\n",
    "                # luminance_min: float,\n",
    "                # luminance_max: float,\n",
    "                # intensity_min: float,\n",
    "                # intensity_max: float,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        pixel_response : Array\n",
    "            The pixel_response to apply to the input psf. Must be a 2-dimensional array\n",
    "            equal to size of the psf at time of application.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # assert pixel_response.shape[0] == 3, \"Pixel response must contain 3 matrices corresponding to gamma fn coeffs\"\n",
    "        # assert luminance_max > luminance_min, \"luminance_max must be greater than luminance_min\"\n",
    "        # assert intensity_max > intensity_min, \"intensity_max must be greater than intensity_min\"\n",
    "\n",
    "        self.pixel_response = jnp.asarray(pixel_response, dtype=float)\n",
    "        self.x_intercepts = self.calc_x_intercepts()\n",
    "        # self.luminance_min = jnp.array(luminance_min, dtype=float)\n",
    "        # self.luminance_max = jnp.array(luminance_max, dtype=float)\n",
    "        # self.intensity_min = jnp.array(intensity_min, dtype=float)\n",
    "        # self.intensity_max = jnp.array(intensity_max, dtype=float)\n",
    "\n",
    "    def calc_x_intercepts(self):\n",
    "        \"\"\"\n",
    "            Calculate the x-intercepts of the gamma function, for input intensity values\n",
    "            that result in curve below x-axis. Think this is just a precision artefact.\n",
    "        \"\"\"\n",
    "        x_int = jnp.power((-self.pixel_response[0] / self.pixel_response[1]), 1/self.pixel_response[2])\n",
    "        \n",
    "        return x_int\n",
    "\n",
    "\n",
    "    def apply(self: dl.layers.detector_layers.DetectorLayer, psf: dl.PSF) -> dl.PSF:\n",
    "        \"\"\"\n",
    "        Applies the layer to the PSF.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        psf : PSF\n",
    "            The psf to operate on.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        psf : PSF\n",
    "            The transformed psf.\n",
    "\n",
    "        \"\"\"\n",
    "        psf_array = jnp.asarray(psf.data, dtype=float)\n",
    "        # # assert psf_array.shape == self.pixel_response[0].shape and\\\n",
    "        # # psf_array.shape == self.pixel_response[1].shape and \\\n",
    "        # # psf_array.shape == self.pixel_response[2].shape, \"PSF and pixel response must have same shape\"\n",
    "\n",
    "        # # remap to [luminance_min, luminance_max] for measured gamma fn \n",
    "        # orig_min, orig_max = psf_array.min(), psf_array.max()\n",
    "        # # print(orig_min, orig_max)\n",
    "        # # data_remapped = psf_array #0.0 + ((1.0 - 0.0)/(orig_max-orig_min))*(psf_array - orig_min)\n",
    "\n",
    "        # # # t1 = jnp.isnan(orig_max-orig_min)\n",
    "        # # # t2 = jnp.isnan(psf_array - orig_min)\n",
    "        # # # print(t1.sum(), t2.sum())\n",
    "        # # # print(\"data remapped max and min:\", data_remapped.max(), data_remapped.min())\n",
    "\n",
    "        # power = psf_array**self.pixel_response[2] # think jnp.power() is causing nan grads\n",
    "        # measured_psf = self.pixel_response[0] + self.pixel_response[1]*power #element-wise power\n",
    "\n",
    "        # # neg_mask = measured_psf < 0.0\n",
    "        # # measured_psf = measured_psf*jnp.invert(neg_mask) + psf_array*neg_mask # take orig values if neg\n",
    "\n",
    "\n",
    "        # # print(\"coeffs: {}, {},{}, input intensity: {} output intensity: {}\".format(self.pixel_response[0][0,0],self.pixel_response[1][0,0],self.pixel_response[2][0,0], psf_array[0,0], measured_psf[0,0]))\n",
    "        \n",
    "        # # # for some reason this is not guaranteed to be in the range of [intensity_min, intensity_max]?? fns calc should be in range\n",
    "        # # # either interpet this as 0 pixel or remap range? \n",
    "        # # Because of floating point precision limitations - very small values show curve below x-axis. Remap to fix this.\n",
    "        # measured_psf = orig_min+ ((1.0 - orig_min)/(measured_psf.max()-measured_psf.min()))*(measured_psf - measured_psf.min())\n",
    "        # # # print(measured_psf.max(), measured_psf.min())\n",
    "\n",
    "        # # # print(self.pixel_response[0][0,0],self.pixel_response[1][0,0],self.pixel_response[2][0,0])\n",
    "        # # # reamap back to original range (in range of [intensity_min, intensity_max] currently)\n",
    "        # # measured_psf = orig_min + ((orig_max - orig_min)/(1.0 - 0.0))*(measured_psf - 0.0)\n",
    "\n",
    "        # # # psf_obj = dl.PSF(data = data_remapped, pixel_scale = psf.pixel_scale)\n",
    "        # # measured_psf = measured_psf.at[measured_psf < 0.0].set(0.0001)\n",
    "        # # psf_obj = dl.PSF(data = jnp.abs(measured_psf), pixel_scale = psf.pixel_scale)\n",
    "        # psf_obj = dl.PSF(data = (measured_psf), pixel_scale = psf.pixel_scale)\n",
    "\n",
    "\n",
    "        psf_obj = dl.PSF(data = psf_array**(1/1), pixel_scale = psf.pixel_scale)\n",
    "\n",
    "\n",
    "        return psf_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simulate Spider -----------------------------------------------------------------#\n",
    "spider = dlu.spider(coords=coords, width=spider_width, angles=[spider_angle])\n",
    "transmission = dlu.combine([circle, spider])*intensity_dist\n",
    "\n",
    "# Zernike aberrations\n",
    "zernike_indicies = jnp.arange(4, 15) # up to 10th noll idxs (excluding piston)\n",
    "coeffs = jnp.zeros(zernike_indicies.shape)\n",
    "basis = dlu.zernike_basis(js=zernike_indicies, coordinates=coords, diameter=aperture_diameter)\n",
    "\n",
    "# Using PointSources instead of single PointSource object to overcome float grad issue when solving for flux\n",
    "# https://github.com/LouisDesdoigts/dLux/issues/271 \n",
    "src = dl.PointSources(wavelengths=[laser_wavelength], flux =jnp.asarray([1e8],dtype=float))\n",
    "# wf_pixel_coords = dlu.pixel_coords(npixels=psf_npix, diameter=wf_diam)\n",
    "# src = GaussResolvedSource(gaussian_param=np.array([10e-2,10e-2]), \n",
    "#                           pixel_coords=wf_pixel_coords, \n",
    "#                           wavelengths=jnp.array([laser_wavelength]), \n",
    "#                           flux=jnp.array([1e8]) # trying to overcome zdx issues\n",
    "#                           )\n",
    "\n",
    "layers = [\n",
    "    # ('intensity_prof', GaussTransmissiveLayer(point_source=src,\n",
    "    #                                           gaussian_param=jnp.array([5e-2,5e-2]),\n",
    "    #                                           pixel_coords=coords,\n",
    "    #                                           det_npix=psf_npix,\n",
    "    #                                           psf_pixel_scale=psf_pixel_scale)),\n",
    "    ('aperture', dl.layers.BasisOptic(basis, transmission, coeffs, normalise=False)),\n",
    "]\n",
    "\n",
    "# Construct Optics\n",
    "optics = dl.AngularOpticalSystem(wf_npixels = wf_npixels, \n",
    "                                diameter=wf_diam, \n",
    "                                layers=layers, \n",
    "                                psf_npixels=psf_npix, \n",
    "                                psf_pixel_scale=psf_pixel_scale,\n",
    "                                oversample=oversample)\n",
    "\n",
    "# ----------------------------------------------------------------------------------#\n",
    "# Create detector layer to characterise non-linear response of BFS det \n",
    "row_start, col_start = 1676, 2532 # Start coord of window on det where data was taken\n",
    "row_len, col_len = 86, 76   # window size of recorded data\n",
    "psf_hlf_sz = 14             # half window sz of cropped data\n",
    "\n",
    "# load in response curve matrices (form of Gamma fn)\n",
    "alpha = np.load(\"data/80us_detector/ALPHA_norm.npy\")[row_start:row_start+row_len, col_start:col_start+col_len]\n",
    "beta = np.load(\"data/80us_detector/BETA_norm.npy\")[row_start:row_start+row_len, col_start:col_start+col_len]\n",
    "gamma = np.load(\"data/80us_detector/GAMMA_norm.npy\")[row_start:row_start+row_len, col_start:col_start+col_len]\n",
    "\n",
    "# Crop, anchored on middle (cropped data will be based on max values, but this occurs close enough to the\n",
    "# middle to estimate here. + detector response is fairly homogenous over small window)\n",
    "middle_row, middle_col = int(alpha.shape[0]/2), int(alpha.shape[1]/2)\n",
    "cropped_alpha = alpha[middle_row-psf_hlf_sz:middle_row+psf_hlf_sz, middle_col-psf_hlf_sz:middle_col+psf_hlf_sz]\n",
    "cropped_beta = beta[middle_row-psf_hlf_sz:middle_row+psf_hlf_sz, middle_col-psf_hlf_sz:middle_col+psf_hlf_sz]\n",
    "cropped_gamma = gamma[middle_row-psf_hlf_sz:middle_row+psf_hlf_sz, middle_col-psf_hlf_sz:middle_col+psf_hlf_sz]\n",
    "\n",
    "pixel_response = jnp.array([cropped_alpha, cropped_beta, cropped_gamma])\n",
    "detector = dl.LayeredDetector([ApplyBFSPixelResponse(pixel_response=pixel_response,\n",
    "                                                    #  luminance_max= 52500, # cd/m^2 for 80us expsure data check BFS_Characterisation.ipynb\n",
    "                                                    #  luminance_min= 0,\n",
    "                                                    #  intensity_min= 255,\n",
    "                                                    #  intensity_max=62992, \n",
    "                                                    # luminance_max= 100, # cd/m^2 for 80us expsure data check BFS_Characterisation.ipynb\n",
    "                                                    #  luminance_min= 0,\n",
    "                                                    #  intensity_min= 0,\n",
    "                                                    #  intensity_max=100, \n",
    "                                                     )])\n",
    "\n",
    "instrument = dl.Telescope(optics, ('source', src), detector)\n",
    "sim_psf = instrument.model()\n",
    "print(sim_psf.min())\n",
    "\n",
    "# Show setup and transmission results\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "# plt.imshow(transmission*instrument.optics.intensity_prof.transmission)\n",
    "plt.imshow(transmission)\n",
    "plt.colorbar()\n",
    "plt.title('Mask Transmission')\n",
    "plt.subplot(1,2,2)\n",
    "norm_psf = PowerNorm(0.2, vmax=sim_psf.max(), vmin=sim_psf.min())\n",
    "print(\"Total flux: {}\".format(sim_psf.sum()))\n",
    "plt.imshow(sim_psf, norm=norm_psf)\n",
    "plt.title('PSF (laser)')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in spider images ⭐️\n",
    "- 09_laser_90deg_200us_0gain_img_stack_batch_0.npy: Spider (90 deg oriented) setup with laser\n",
    "- 10_laser_90deg_200us_0gain_img_stack_batch_0.npy: Same setup as above scenario, data taken ~1hr later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/spider/09_laser_90deg_200us_0gain_img_stack_batch_0.npy\" #data/spider/08_laser_90deg_img_stack.npy\"\n",
    "data = np.load(fname)\n",
    "data = data[116,:,:] # using the most still frame (find_still_frame.py)\n",
    "\n",
    "bckgnd = np.load(\"data/spider/10_laser_90deg_bckgnd_200us_0gain_img_stack_batch_0.npy\")\n",
    "bckgnd = np.mean(bckgnd)\n",
    "data = data - bckgnd\n",
    "\n",
    "# apply non-linearity response\n",
    "data_remapped = 0.0 + ((1.0 - 0.0)/(data.max()-data.min()))*(data - data.min()) #[0,1] otput range\n",
    "# data_lin = np.power((data_remapped-alpha)/beta, (1/gamma))\n",
    "data_lin = np.power((data_remapped-np.flip(alpha,axis=(0,1)))/np.flip(beta,axis=(0,1)), (1/np.flip(gamma,axis=(0,1))))\n",
    "\n",
    "\n",
    "# Scale intensity\n",
    "data = data_lin\n",
    "current_range = data.max() - data.min()\n",
    "new_range = sim_psf.max() - sim_psf.min()\n",
    "scaled_data = ( (data - data.min()) * new_range )/current_range + sim_psf.min()\n",
    "# new_range = data.max() - 0\n",
    "# scaled_data = ( (data - data.min()) * new_range )/current_range + 0\n",
    "\n",
    "psf_center_idx = np.unravel_index(np.argmax(scaled_data, axis=None), scaled_data.shape)\n",
    "scaled_data = scaled_data[psf_center_idx[0]-psf_hlf_sz:psf_center_idx[0]+psf_hlf_sz,\n",
    "                            psf_center_idx[1]-psf_hlf_sz:psf_center_idx[1]+psf_hlf_sz]\n",
    "\n",
    "data = data[psf_center_idx[0]-psf_hlf_sz:psf_center_idx[0]+psf_hlf_sz,\n",
    "                            psf_center_idx[1]-psf_hlf_sz:psf_center_idx[1]+psf_hlf_sz]\n",
    "data = data + sim_psf.min() # ensure mu = 0 for k !=0 does not occur (logpmf shits itself)\n",
    "\n",
    "print(\"Total flux (Raw): {}\".format(data.sum()))\n",
    "print(\"Total flux (Scaled): {}\".format(scaled_data.sum()))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(scaled_data, norm=norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title(\"Data (scaled)\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(sim_psf, norm=norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title(\"Simulated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @zdx.filter_jit\n",
    "# @zdx.filter_value_and_grad(param)\n",
    "# def loss_fn_mse(model, data, wavelength_center):\n",
    "\n",
    "#     simu_psf = model.propagate_mono(wavelength_center)\n",
    "\n",
    "#     mse = 1/simu_psf.size * ((data-simu_psf)**2).sum()\n",
    "\n",
    "#     return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    'aperture.coefficients',\n",
    "    'source.position',\n",
    "    # 'optics.intensity_prof.gauss_param',\n",
    "    'source.flux', \n",
    "    # 'detector.ApplyBFSPixelResponse.pixel_response',\n",
    "    ]\n",
    "@zdx.filter_jit\n",
    "@zdx.filter_value_and_grad(params)\n",
    "def loss_fn_gaussian(model, data):\n",
    "\n",
    "    simu_psf = model.model()\n",
    "\n",
    "    uncertainty = 0.1 # 10% err per pix TODO try increasing\n",
    "\n",
    "    loss = -jsp.stats.norm.logpdf(x=simu_psf, loc=data, scale=data*uncertainty).sum()\n",
    "\n",
    "    return loss\n",
    "@zdx.filter_jit\n",
    "@zdx.filter_value_and_grad(params)\n",
    "def loss_fn_poisson(model, data):\n",
    "\n",
    "    simu_psf = model.model()\n",
    "\n",
    "    loss = -jsp.stats.poisson.logpmf(k=simu_psf, mu=data).sum()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poiss_loss, poiss_grads = loss_fn_poisson(model = instrument, data = scaled_data)\n",
    "\n",
    "print(poiss_loss)\n",
    "print(poiss_grads.aperture.coefficients)\n",
    "\n",
    "psf = instrument.model()\n",
    "t = -jsp.stats.poisson.logpmf(k=psf, mu=scaled_data)\n",
    "print(t[0,0], psf[0,0], scaled_data[0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-9\n",
    "# optimisers = [\n",
    "#             optax.adam(optax.linear_schedule(init_value=learning_rate, end_value=0, transition_begin=5000, transition_steps=1)),\n",
    "#             optax.adam(optax.linear_schedule(init_value=learning_rate, end_value=0, transition_begin=5000, transition_steps=1)),\n",
    "#             # optax.adam(optax.piecewise_constant_schedule(init_value=1e-2*1e4, boundaries_and_scales={400: int(1e4)})),\n",
    "#             optax.adam(optax.linear_schedule(init_value=0, end_value=1e-3, transition_begin=5000, transition_steps=1)),\n",
    "#             optax.adam(learning_rate=1e6),\n",
    "#             # optax.adam(optax.linear_schedule(init_value=1e4, end_value=0, transition_begin=5000, transition_steps=1)),\n",
    "#             # optax.adam(optax.linear_schedule(init_value=0, end_value=1e6, transition_begin=500, transition_steps=1)),\n",
    "#             # optax.adam(learning_rate=1e6),\n",
    "#             # optax.adam(learning_rate=1e-3),\n",
    "#               ]\n",
    "optimisers = [\n",
    "            optax.adam(learning_rate=learning_rate),\n",
    "            optax.adam(learning_rate=learning_rate),\n",
    "            # optax.adam(learning_rate=1e-4),\n",
    "            optax.adam(learning_rate=1e6),\n",
    "            # optax.adam(learning_rate=1e-2),\n",
    "              ]\n",
    "\n",
    "\n",
    "# Optimise flux first\n",
    "optim, opt_state = zdx.get_optimiser(instrument, params, optimisers) # Needs to be iterable param (i.e. accessible via instrument class)\n",
    "\n",
    "progress_bar = tqdm(range(5000), desc='Loss: ')\n",
    "\n",
    "# Run optimisation loop \n",
    "net_losses, Coeffs, Positions, Fluxes, Dist_sum, Pix_resp = [],[],[],[], [], []\n",
    "for i in progress_bar:\n",
    "    poiss_loss, poiss_grads = loss_fn_poisson(model = instrument, data = scaled_data)\n",
    "    # print(poiss_loss)\n",
    "    # print(poiss_grads.aperture.coefficients)\n",
    "    # print(poiss_grads.source.position)\n",
    "\n",
    "    updates, opt_state = optim.update(poiss_grads, opt_state)\n",
    "    instrument = zdx.apply_updates(instrument, updates) \n",
    "\n",
    "    net_losses.append(poiss_loss)\n",
    "    Fluxes.append(instrument.source.flux)\n",
    "    Coeffs.append(instrument.aperture.coefficients)\n",
    "    Positions.append(instrument.source.position)\n",
    "    # Dist_sum.append(instrument.optics.intensity_prof.gauss_param)\n",
    "    Pix_resp.append(instrument.detector.ApplyBFSPixelResponse.pixel_response)\n",
    "    \n",
    "    progress_bar.set_postfix({'Loss': poiss_loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_psf = instrument.model()\n",
    "# print(instrument.source.flux)\n",
    "# print(instrument.aperture.coefficients)\n",
    "\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(sim_psf**0.2)\n",
    "# plt.colorbar()\n",
    "\n",
    "# print(sim_psf.min(), sim_psf.max())\n",
    "# plt.subplot(1,2,2)\n",
    "# t = -jsp.stats.poisson.logpmf(k=sim_psf, mu=scaled_data)\n",
    "# plt.imshow(t)\n",
    "\n",
    "# print(sim_psf[0,0], scaled_data[0,0], -jsp.stats.poisson.logpmf(k=sim_psf[0,0], mu=scaled_data[0,0]))\n",
    "\n",
    "# print(-jsp.stats.poisson.logpmf(k=sim_psf, mu=scaled_data).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(np.array(net_losses))\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Training History\")\n",
    "ax.set_xlabel(\"Training Epoch\")\n",
    "ax.set_ylabel(\"Poisson Log-Likelihood\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 17)\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.subplot(1,5,1)\n",
    "plt.plot(np.asarray(Positions)[:,0,0], label=\"Position X\")\n",
    "plt.plot(np.asarray(Positions)[:,0,1], label=\"Position Y\")\n",
    "# plt.plot(np.asarray(Positions)[:,0], label=\"Position X\")\n",
    "# plt.plot(np.asarray(Positions)[:,1], label=\"Position Y\")\n",
    "plt.title(\"Position\")\n",
    "plt.legend()\n",
    "plt.subplot(1,5,2)\n",
    "plt.plot(np.asarray(Dist_sum))\n",
    "plt.title(\"Source Gauss params\")\n",
    "plt.subplot(1,5,3)\n",
    "arr_coeffs = np.asarray(Coeffs)\n",
    "for i in range(len(Coeffs[0])):\n",
    "    label = \"Coeff \" + str(zernike_indicies[i])\n",
    "    plt.plot(arr_coeffs[:,i], label=label)\n",
    "plt.legend()\n",
    "plt.subplot(1,5,4)\n",
    "plt.plot(np.asarray(Fluxes))\n",
    "plt.title(\"Flux\")\n",
    "plt.subplot(1,5,5)\n",
    "# plt.plot(np.asarray(Pix_resp))\n",
    "plt.title(\"Pixel Response Coeffs\")\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "norm_psf = PowerNorm(0.2, vmax=scaled_data.max(), vmin=scaled_data.min())\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(scaled_data, norm=norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title('Data')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "model_psf = instrument.model()\n",
    "current_range = model_psf.max() - model_psf.min()\n",
    "new_range = scaled_data.max() - scaled_data.min()\n",
    "model_psf = ( (model_psf - model_psf.min()) * new_range )/current_range + scaled_data.min()\n",
    "norm_psf = PowerNorm(0.2, vmax=model_psf.max(), vmin=model_psf.min())\n",
    "mask = np.ones(scaled_data.shape)\n",
    "mask[scaled_data < 0.01] = 0\n",
    "plt.imshow(model_psf*mask, norm=norm_psf)\n",
    "plt.title('Model')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "resid = scaled_data - model_psf\n",
    "# resid = data - model_psf\n",
    "plt.imshow(resid, cmap='bwr', vmax = np.abs(resid).max(), vmin = -np.abs(resid).max())\n",
    "plt.colorbar()\n",
    "plt.title('Residuals')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "opd = instrument.aperture.eval_basis()\n",
    "plt.imshow(opd*transmission, cmap='viridis')\n",
    "plt.title('Retrieved Aberrations')\n",
    "plt.colorbar()\n",
    "\n",
    "run_coeffs.append(instrument.optics.aperture.coefficients)\n",
    "run_poses.append(Positions)\n",
    "run_fluxes.append(Fluxes)\n",
    "print(\"Optimised Position: {}\\nFlux: {}\\nCoefficients: {}\".format(instrument.source.position, instrument.source.flux, instrument.aperture.coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(scaled_data, cmap='bone_r')\n",
    "ax[1].imshow(model_psf, cmap='bone_r') \n",
    "\n",
    "point = [14, 14]\n",
    "\n",
    "for i in [0, 1]:\n",
    "    ax[i].scatter(*point, marker='x', color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Found coefficients for noll idxs: {}\\n{}\".format(zernike_indicies, instrument.optics.aperture.coefficients))\n",
    "\n",
    "run1_coeffs = instrument.optics.aperture.coefficients\n",
    "run1_pos = Positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try with second data set... (1hr apart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialise model\n",
    "optics = dl.AngularOpticalSystem(wf_npixels = wf_npixels, \n",
    "                                diameter=wf_diam, \n",
    "                                layers=layers, \n",
    "                                psf_npixels=psf_npix, \n",
    "                                psf_pixel_scale=psf_pixel_scale,\n",
    "                                oversample=oversample)\n",
    "\n",
    "instrument = dl.Telescope(optics, ('source', src), detector)\n",
    "print(instrument.optics.aperture.coefficients, instrument.source.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/spider/10_laser_90deg_200us_0gain_img_stack_batch_0.npy\" #data/spider/08_laser_90deg_img_stack.npy\"\n",
    "data = np.load(fname)\n",
    "data = data[7,:,:]\n",
    "\n",
    "bckgnd = np.load(\"data/spider/10_laser_90deg_bckgnd_200us_0gain_img_stack_batch_0.npy\") \n",
    "bckgnd = np.mean(bckgnd)\n",
    "data = data - bckgnd\n",
    "\n",
    "# Scale intensity\n",
    "current_range = data.max() - data.min()\n",
    "new_range = sim_psf.max() - sim_psf.min()\n",
    "scaled_data = ( (data - data.min()) * new_range )/current_range + sim_psf.min()\n",
    "\n",
    "psf_center_idx = np.unravel_index(np.argmax(scaled_data, axis=None), scaled_data.shape)\n",
    "scaled_data = scaled_data[psf_center_idx[0]-psf_hlf_sz:psf_center_idx[0]+psf_hlf_sz,\n",
    "                            psf_center_idx[1]-psf_hlf_sz:psf_center_idx[1]+psf_hlf_sz]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(scaled_data, norm = norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title(\"Data\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(sim_psf, norm = norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title(\"Simulated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-9\n",
    "optimisers = [\n",
    "            optax.adam(learning_rate=learning_rate),\n",
    "            optax.adam(learning_rate=learning_rate),\n",
    "            # optax.adam(learning_rate=1e-4),\n",
    "            optax.adam(learning_rate=1e6),\n",
    "            # optax.adam(learning_rate=1e-2),\n",
    "              ]\n",
    "\n",
    "\n",
    "# Optimise flux first\n",
    "optim, opt_state = zdx.get_optimiser(instrument, params, optimisers) # Needs to be iterable param (i.e. accessible via instrument class)\n",
    "\n",
    "progress_bar = tqdm(range(5000), desc='Loss: ')\n",
    "\n",
    "# Run optimisation loop \n",
    "net_losses, Coeffs, Positions, Fluxes, Dist_sum, Pix_resp = [],[],[],[], [], []\n",
    "for i in progress_bar:\n",
    "    poiss_loss, poiss_grads = loss_fn_poisson(model = instrument, data = scaled_data)\n",
    "\n",
    "    updates, opt_state = optim.update(poiss_grads, opt_state)\n",
    "    instrument = zdx.apply_updates(instrument, updates) \n",
    "\n",
    "    net_losses.append(poiss_loss)\n",
    "    Fluxes.append(instrument.source.flux)\n",
    "    Coeffs.append(instrument.aperture.coefficients)\n",
    "    Positions.append(instrument.source.position)\n",
    "    # Dist_sum.append(instrument.optics.intensity_prof.gauss_param)\n",
    "    Pix_resp.append(instrument.detector.ApplyBFSPixelResponse.pixel_response)\n",
    "    \n",
    "    progress_bar.set_postfix({'Loss': poiss_loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(np.array(net_losses))\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Training History\")\n",
    "ax.set_xlabel(\"Training Epoch\")\n",
    "ax.set_ylabel(\"Poisson Log-Likelihood\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 17)\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.subplot(1,5,1)\n",
    "plt.plot(np.asarray(Positions)[:,0,0], label=\"Position X\")\n",
    "plt.plot(np.asarray(Positions)[:,0,1], label=\"Position Y\")\n",
    "# plt.plot(np.asarray(Positions)[:,0], label=\"Position X\")\n",
    "# plt.plot(np.asarray(Positions)[:,1], label=\"Position Y\")\n",
    "plt.title(\"Position\")\n",
    "plt.legend()\n",
    "plt.subplot(1,5,2)\n",
    "plt.plot(np.asarray(Dist_sum))\n",
    "plt.title(\"Source Gauss params\")\n",
    "plt.subplot(1,5,3)\n",
    "arr_coeffs = np.asarray(Coeffs)\n",
    "for i in range(len(Coeffs[0])):\n",
    "    label = \"Coeff \" + str(zernike_indicies[i])\n",
    "    plt.plot(arr_coeffs[:,i], label=label)\n",
    "plt.legend()\n",
    "plt.subplot(1,5,4)\n",
    "plt.plot(np.asarray(Fluxes))\n",
    "plt.title(\"Flux\")\n",
    "plt.subplot(1,5,5)\n",
    "plt.plot(np.asarray(Pix_resp))\n",
    "plt.title(\"Pixel Response Coeffs\")\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "norm_psf = PowerNorm(0.2, vmax=scaled_data.max(), vmin=scaled_data.min())\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(scaled_data, norm=norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title('Data')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "model_psf = instrument.model()\n",
    "current_range = model_psf.max() - model_psf.min()\n",
    "new_range = scaled_data.max() - scaled_data.min()\n",
    "model_psf = ( (model_psf - model_psf.min()) * new_range )/current_range + scaled_data.min()\n",
    "norm_psf = PowerNorm(0.2, vmax=model_psf.max(), vmin=model_psf.min())\n",
    "mask = np.ones(scaled_data.shape)\n",
    "mask[scaled_data < 0.01] = 0\n",
    "plt.imshow(model_psf*mask, norm=norm_psf)\n",
    "plt.title('Model')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "resid = scaled_data - model_psf\n",
    "# resid = data - model_psf\n",
    "plt.imshow(resid, cmap='bwr', vmax = np.abs(resid).max(), vmin = -np.abs(resid).max())\n",
    "plt.colorbar()\n",
    "plt.title('Residuals')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "opd = instrument.aperture.eval_basis()\n",
    "plt.imshow(opd*transmission, cmap='viridis')\n",
    "plt.title('Retrieved Aberrations')\n",
    "plt.colorbar()\n",
    "\n",
    "run_coeffs.append(instrument.optics.aperture.coefficients)\n",
    "run_poses.append(Positions)\n",
    "run_fluxes.append(Fluxes)\n",
    "print(\"Optimised Position: {}\\nFlux: {}\\nCoefficients: {}\".format(instrument.source.position, instrument.source.flux, instrument.aperture.coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i, coeffs in enumerate(run_coeffs):\n",
    "    plt.plot(zernike_indicies,coeffs, label='Run ' + str(i))\n",
    "plt.xlabel('Noll Index')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.title(\"Phase Retrieval 1hr Apart\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets look at different orientation of spider 🕷️🕸️\n",
    "- 11_laser_180deg_80us_3gain_img_stack_batch_0.npy\n",
    "- 12_laser_180deg_80us_3gain_img_stack_batch_0.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circle = dlu.circle(coords=coords, radius=aperture_diameter/2) \n",
    "spider = dlu.spider(coords=coords, width=spider_width, angles=[180]) \n",
    "transmission = dlu.combine([circle, spider]) \n",
    "transmission *= intensity_dist\n",
    "\n",
    "# Zernike aberrations\n",
    "coeffs = np.zeros(zernike_indicies.shape)\n",
    "basis = dlu.zernike_basis(js=zernike_indicies, coordinates=coords, diameter=aperture_diameter)\n",
    "\n",
    "layers = [\n",
    "    ('aperture', dl.layers.BasisOptic(basis, transmission, coeffs, normalise=False))\n",
    "]\n",
    "\n",
    "# Construct Optics\n",
    "optics = dl.AngularOpticalSystem(wf_npixels = wf_npixels, \n",
    "                                diameter=wf_diam, \n",
    "                                layers=layers, \n",
    "                                psf_npixels=psf_npix, \n",
    "                                psf_pixel_scale=psf_pixel_scale,\n",
    "                                oversample=oversample)\n",
    "instrument = dl.Telescope(optics, ('source', src), detector)\n",
    "\n",
    "\n",
    "sim_psf = instrument.model()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(transmission)\n",
    "plt.colorbar()\n",
    "plt.title('Model 1 Transmission')\n",
    "plt.subplot(2,2,2)\n",
    "norm_psf = PowerNorm(0.5, vmax=sim_psf.max(), vmin=sim_psf.min())\n",
    "plt.imshow(sim_psf, norm=norm_psf)\n",
    "plt.title('Model 1 (laser)')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/spider/11_laser_180deg_80us_3gain_img_stack_batch_0.npy\" #data/spider/08_laser_90deg_img_stack.npy\"\n",
    "data = np.load(fname)\n",
    "data = data[131,:,:]\n",
    "\n",
    "bckgnd = np.load(\"data/spider/12_laser_180deg_bckgnd_80us_3gain_img_stack_batch_0.npy\") \n",
    "bckgnd = np.mean(bckgnd)\n",
    "data = data - bckgnd\n",
    "\n",
    "# Scale intensity\n",
    "current_range = data.max() - data.min()\n",
    "new_range = sim_psf.max() - sim_psf.min()\n",
    "scaled_data = ( (data - data.min()) * new_range )/current_range + sim_psf.min()\n",
    "\n",
    "psf_center_idx = np.unravel_index(np.argmax(scaled_data, axis=None), scaled_data.shape)\n",
    "scaled_data = scaled_data[psf_center_idx[0]-psf_hlf_sz:psf_center_idx[0]+psf_hlf_sz,\n",
    "                            psf_center_idx[1]-psf_hlf_sz:psf_center_idx[1]+psf_hlf_sz]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(scaled_data, norm = norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title(\"Data\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(sim_psf, norm = norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title(\"Simulated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-9\n",
    "optimisers = [\n",
    "            optax.adam(learning_rate=learning_rate),\n",
    "            optax.adam(learning_rate=learning_rate),\n",
    "            # optax.adam(learning_rate=1e-4),\n",
    "            optax.adam(learning_rate=1e6),\n",
    "            # optax.adam(learning_rate=1e-2),\n",
    "              ]\n",
    "\n",
    "\n",
    "# Optimise flux first\n",
    "optim, opt_state = zdx.get_optimiser(instrument, params, optimisers) # Needs to be iterable param (i.e. accessible via instrument class)\n",
    "\n",
    "progress_bar = tqdm(range(5000), desc='Loss: ')\n",
    "\n",
    "# Run optimisation loop \n",
    "net_losses, Coeffs, Positions, Fluxes, Dist_sum, Pix_resp = [],[],[],[], [], []\n",
    "for i in progress_bar:\n",
    "    poiss_loss, poiss_grads = loss_fn_poisson(model = instrument, data = scaled_data)\n",
    "\n",
    "    updates, opt_state = optim.update(poiss_grads, opt_state)\n",
    "    instrument = zdx.apply_updates(instrument, updates) \n",
    "\n",
    "    net_losses.append(poiss_loss)\n",
    "    Fluxes.append(instrument.source.flux)\n",
    "    Coeffs.append(instrument.aperture.coefficients)\n",
    "    Positions.append(instrument.source.position)\n",
    "    # Dist_sum.append(instrument.optics.intensity_prof.gauss_param)\n",
    "    Pix_resp.append(instrument.detector.ApplyBFSPixelResponse.pixel_response)\n",
    "    \n",
    "    progress_bar.set_postfix({'Loss': poiss_loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(np.array(net_losses))\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Training History\")\n",
    "ax.set_xlabel(\"Training Epoch\")\n",
    "ax.set_ylabel(\"Poisson Log-Likelihood\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 17)\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.subplot(1,5,1)\n",
    "plt.plot(np.asarray(Positions)[:,0,0], label=\"Position X\")\n",
    "plt.plot(np.asarray(Positions)[:,0,1], label=\"Position Y\")\n",
    "# plt.plot(np.asarray(Positions)[:,0], label=\"Position X\")\n",
    "# plt.plot(np.asarray(Positions)[:,1], label=\"Position Y\")\n",
    "plt.title(\"Position\")\n",
    "plt.legend()\n",
    "plt.subplot(1,5,2)\n",
    "plt.plot(np.asarray(Dist_sum))\n",
    "plt.title(\"Source Gauss params\")\n",
    "plt.subplot(1,5,3)\n",
    "arr_coeffs = np.asarray(Coeffs)\n",
    "for i in range(len(Coeffs[0])):\n",
    "    label = \"Coeff \" + str(zernike_indicies[i])\n",
    "    plt.plot(arr_coeffs[:,i], label=label)\n",
    "plt.legend()\n",
    "plt.subplot(1,5,4)\n",
    "plt.plot(np.asarray(Fluxes))\n",
    "plt.title(\"Flux\")\n",
    "plt.subplot(1,5,5)\n",
    "plt.plot(np.asarray(Pix_resp))\n",
    "plt.title(\"Pixel Response Coeffs\")\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "norm_psf = PowerNorm(0.2, vmax=scaled_data.max(), vmin=scaled_data.min())\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(scaled_data, norm=norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title('Data')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "model_psf = instrument.model()\n",
    "current_range = model_psf.max() - model_psf.min()\n",
    "new_range = scaled_data.max() - scaled_data.min()\n",
    "model_psf = ( (model_psf - model_psf.min()) * new_range )/current_range + scaled_data.min()\n",
    "norm_psf = PowerNorm(0.2, vmax=model_psf.max(), vmin=model_psf.min())\n",
    "mask = np.ones(scaled_data.shape)\n",
    "mask[scaled_data < 0.01] = 0\n",
    "plt.imshow(model_psf*mask, norm=norm_psf)\n",
    "plt.title('Model')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "resid = scaled_data - model_psf\n",
    "# resid = data - model_psf\n",
    "plt.imshow(resid, cmap='bwr', vmax = np.abs(resid).max(), vmin = -np.abs(resid).max())\n",
    "plt.colorbar()\n",
    "plt.title('Residuals')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "opd = instrument.aperture.eval_basis()\n",
    "plt.imshow(opd*transmission, cmap='viridis')\n",
    "plt.title('Retrieved Aberrations')\n",
    "plt.colorbar()\n",
    "\n",
    "run_coeffs.append(instrument.optics.aperture.coefficients)\n",
    "run_poses.append(Positions)\n",
    "run_fluxes.append(Fluxes)\n",
    "print(\"Optimised Position: {}\\nFlux: {}\\nCoefficients: {}\".format(instrument.source.position, instrument.source.flux, instrument.aperture.coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialise model\n",
    "optics = dl.AngularOpticalSystem(wf_npixels = wf_npixels, \n",
    "                                diameter=wf_diam, \n",
    "                                layers=layers, \n",
    "                                psf_npixels=psf_npix, \n",
    "                                psf_pixel_scale=psf_pixel_scale,\n",
    "                                oversample=oversample)\n",
    "\n",
    "instrument = dl.Telescope(optics, ('source', src), detector)\n",
    "print(instrument.optics.aperture.coefficients, instrument.source.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/spider/12_laser_180deg_80us_3gain_img_stack_batch_0.npy\" #data/spider/08_laser_90deg_img_stack.npy\"\n",
    "data = np.load(fname)\n",
    "data = data[68,:,:]\n",
    "\n",
    "bckgnd = np.load(\"data/spider/12_laser_180deg_bckgnd_80us_3gain_img_stack_batch_0.npy\") \n",
    "bckgnd = np.mean(bckgnd)\n",
    "data = data - bckgnd\n",
    "\n",
    "# Scale intensity\n",
    "current_range = data.max() - data.min()\n",
    "new_range = sim_psf.max() - sim_psf.min()\n",
    "scaled_data = ( (data - data.min()) * new_range )/current_range + sim_psf.min()\n",
    "\n",
    "psf_center_idx = np.unravel_index(np.argmax(scaled_data, axis=None), scaled_data.shape)\n",
    "scaled_data = scaled_data[psf_center_idx[0]-psf_hlf_sz:psf_center_idx[0]+psf_hlf_sz,\n",
    "                            psf_center_idx[1]-psf_hlf_sz:psf_center_idx[1]+psf_hlf_sz]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(scaled_data, norm = norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title(\"Data\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(sim_psf, norm = norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title(\"Simulated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-9\n",
    "optimisers = [\n",
    "            optax.adam(learning_rate=learning_rate),\n",
    "            optax.adam(learning_rate=learning_rate),\n",
    "            # optax.adam(learning_rate=1e-4),\n",
    "            optax.adam(learning_rate=1e6),\n",
    "            # optax.adam(learning_rate=1e-2),\n",
    "              ]\n",
    "\n",
    "\n",
    "# Optimise flux first\n",
    "optim, opt_state = zdx.get_optimiser(instrument, params, optimisers) # Needs to be iterable param (i.e. accessible via instrument class)\n",
    "\n",
    "progress_bar = tqdm(range(5000), desc='Loss: ')\n",
    "\n",
    "# Run optimisation loop \n",
    "net_losses, Coeffs, Positions, Fluxes, Dist_sum, Pix_resp = [],[],[],[], [], []\n",
    "for i in progress_bar:\n",
    "    poiss_loss, poiss_grads = loss_fn_poisson(model = instrument, data = scaled_data)\n",
    "\n",
    "    updates, opt_state = optim.update(poiss_grads, opt_state)\n",
    "    instrument = zdx.apply_updates(instrument, updates) \n",
    "\n",
    "    net_losses.append(poiss_loss)\n",
    "    Fluxes.append(instrument.source.flux)\n",
    "    Coeffs.append(instrument.aperture.coefficients)\n",
    "    Positions.append(instrument.source.position)\n",
    "    # Dist_sum.append(instrument.optics.intensity_prof.gauss_param)\n",
    "    Pix_resp.append(instrument.detector.ApplyBFSPixelResponse.pixel_response)\n",
    "    \n",
    "    progress_bar.set_postfix({'Loss': poiss_loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(np.array(net_losses))\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Training History\")\n",
    "ax.set_xlabel(\"Training Epoch\")\n",
    "ax.set_ylabel(\"Poisson Log-Likelihood\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 17)\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.subplot(1,5,1)\n",
    "plt.plot(np.asarray(Positions)[:,0,0], label=\"Position X\")\n",
    "plt.plot(np.asarray(Positions)[:,0,1], label=\"Position Y\")\n",
    "# plt.plot(np.asarray(Positions)[:,0], label=\"Position X\")\n",
    "# plt.plot(np.asarray(Positions)[:,1], label=\"Position Y\")\n",
    "plt.title(\"Position\")\n",
    "plt.legend()\n",
    "plt.subplot(1,5,2)\n",
    "plt.plot(np.asarray(Dist_sum))\n",
    "plt.title(\"Source Gauss params\")\n",
    "plt.subplot(1,5,3)\n",
    "arr_coeffs = np.asarray(Coeffs)\n",
    "for i in range(len(Coeffs[0])):\n",
    "    label = \"Coeff \" + str(zernike_indicies[i])\n",
    "    plt.plot(arr_coeffs[:,i], label=label)\n",
    "plt.legend()\n",
    "plt.subplot(1,5,4)\n",
    "plt.plot(np.asarray(Fluxes))\n",
    "plt.title(\"Flux\")\n",
    "plt.subplot(1,5,5)\n",
    "plt.plot(np.asarray(Pix_resp))\n",
    "plt.title(\"Pixel Response Coeffs\")\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "norm_psf = PowerNorm(0.2, vmax=scaled_data.max(), vmin=scaled_data.min())\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(scaled_data, norm=norm_psf)\n",
    "plt.colorbar()\n",
    "plt.title('Data')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "model_psf = instrument.model()\n",
    "current_range = model_psf.max() - model_psf.min()\n",
    "new_range = scaled_data.max() - scaled_data.min()\n",
    "model_psf = ( (model_psf - model_psf.min()) * new_range )/current_range + scaled_data.min()\n",
    "norm_psf = PowerNorm(0.2, vmax=model_psf.max(), vmin=model_psf.min())\n",
    "mask = np.ones(scaled_data.shape)\n",
    "mask[scaled_data < 0.01] = 0\n",
    "plt.imshow(model_psf*mask, norm=norm_psf)\n",
    "plt.title('Model')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "resid = scaled_data - model_psf\n",
    "# resid = data - model_psf\n",
    "plt.imshow(resid, cmap='bwr', vmax = np.abs(resid).max(), vmin = -np.abs(resid).max())\n",
    "plt.colorbar()\n",
    "plt.title('Residuals')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "opd = instrument.aperture.eval_basis()\n",
    "plt.imshow(opd*transmission, cmap='viridis')\n",
    "plt.title('Retrieved Aberrations')\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"Found coefficients for noll idxs: {}\\n{}\".format(zernike_indicies, instrument.optics.aperture.coefficients))\n",
    "\n",
    "run_coeffs.append(instrument.optics.aperture.coefficients)\n",
    "run_poses.append(Positions)\n",
    "run_fluxes.append(Fluxes)\n",
    "\n",
    "print(\"Optimised Position: {}\\nFlux: {}\\nCoefficients: {}\".format(instrument.source.position, instrument.source.flux, instrument.aperture.coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i, coeffs in enumerate(run_coeffs):\n",
    "    plt.plot(zernike_indicies,coeffs, label='Run ' + str(i))\n",
    "plt.xlabel('Noll Index')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.grid()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(2,1,1)\n",
    "for i, pos in enumerate(run_poses):\n",
    "    plt.plot(np.asarray(pos)[:,0,0], label='Run ' + str(i))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('X-Position')\n",
    "plt.grid()\n",
    "plt.subplot(2,1,2)\n",
    "for i, pos in enumerate(run_poses):\n",
    "    plt.plot(np.asarray(pos)[:,0,1], label='Run ' + str(i))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Y-Position')\n",
    "plt.grid()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i, flux in enumerate(run_fluxes):\n",
    "    plt.plot(np.asarray(flux), label='Run ' + str(i))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Flux')\n",
    "plt.legend()\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try ✨Phase Diversity (sort of)✨ Using two different Spider Orientations ☀️\n",
    "- Phase Diversity involves taking a second image with a known aberration applied. We have just taken a second image\n",
    "with a different known spider orientation, but we can optimise using both scenarios simultaneously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simulate Spider -----------------------------------------------------------------#\n",
    "circle = dlu.circle(coords=coords, radius=aperture_diameter/2) \n",
    "spider = dlu.spider(coords=coords, width=spider_width, angles=[180]) \n",
    "transmission = dlu.combine([circle, spider]) \n",
    "transmission *= intensity_dist\n",
    "\n",
    "# Zernike aberrations\n",
    "coeffs = np.zeros(zernike_indicies.shape)\n",
    "basis = dlu.zernike_basis(js=zernike_indicies, coordinates=coords, diameter=aperture_diameter)\n",
    "\n",
    "layers = [\n",
    "    ('aperture', dl.layers.BasisOptic(basis, transmission, coeffs, normalise=False))\n",
    "]\n",
    "\n",
    "# Construct Optics\n",
    "optics_1 = dl.AngularOpticalSystem(wf_npixels = wf_npixels, \n",
    "                                diameter=wf_diam, \n",
    "                                layers=layers, \n",
    "                                psf_npixels=psf_npix, \n",
    "                                psf_pixel_scale=psf_pixel_scale,\n",
    "                                oversample=oversample)\n",
    "model_sp0 = dl.Telescope(optics_1, ('source', src), detector)\n",
    "\n",
    "\n",
    "sim_psf = model_sp0.model()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(transmission)\n",
    "plt.colorbar()\n",
    "plt.title('Model 1 Transmission')\n",
    "plt.subplot(2,2,2)\n",
    "norm_psf = PowerNorm(0.5, vmax=sim_psf.max(), vmin=sim_psf.min())\n",
    "plt.imshow(sim_psf, norm=norm_psf)\n",
    "plt.title('Model 1 (laser)')\n",
    "plt.colorbar()\n",
    "\n",
    "spider = dlu.spider(coords=coords, width=spider_width, angles=[spider_angle]) \n",
    "transmission = dlu.combine([circle, spider]) \n",
    "transmission *= intensity_dist\n",
    "layers = [\n",
    "    ('aperture', dl.layers.BasisOptic(basis, transmission, coeffs, normalise=False))\n",
    "]\n",
    "\n",
    "optics_2 = dl.AngularOpticalSystem(wf_npixels = wf_npixels, \n",
    "                                diameter=wf_diam, \n",
    "                                layers=layers, \n",
    "                                psf_npixels=psf_npix, \n",
    "                                psf_pixel_scale=psf_pixel_scale,\n",
    "                                oversample=oversample)\n",
    "model_sp270 = dl.Telescope(optics_2, ('source', src), detector)\n",
    "\n",
    "sim_psf = model_sp270.model()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(transmission)\n",
    "plt.colorbar()\n",
    "plt.title('Model 2 Transmission')\n",
    "plt.subplot(2,2,4)\n",
    "norm_psf = PowerNorm(0.5, vmax=sim_psf.max(), vmin=sim_psf.min())\n",
    "plt.imshow(sim_psf, norm=norm_psf)\n",
    "plt.title('Model 2')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PSFS = []\n",
    "fnames = [\"data/spider/11_laser_180deg_80us_3gain_img_stack_batch_0.npy\", \"data/spider/10_laser_90deg_200us_0gain_img_stack_batch_0.npy\"]\n",
    "            # model with spider at 0deg                            model with spider at 270deg\n",
    "still_frame_idx = [131,7]\n",
    "for i in range(len(fnames)):\n",
    "    fname = fnames[i]\n",
    "    data = np.load(fname)\n",
    "    data = data[still_frame_idx[i],:,:]\n",
    "\n",
    "    # Scale intensity\n",
    "    current_range = data.max() - data.min()\n",
    "    new_range = sim_psf.max() - sim_psf.min()\n",
    "    scaled_data = ( (data - data.min()) * new_range )/current_range + sim_psf.min()\n",
    "\n",
    "    psf_center_idx = np.unravel_index(np.argmax(scaled_data, axis=None), scaled_data.shape)\n",
    "    scaled_data = scaled_data[psf_center_idx[0]-psf_hlf_sz:psf_center_idx[0]+psf_hlf_sz,\n",
    "                                psf_center_idx[1]-psf_hlf_sz:psf_center_idx[1]+psf_hlf_sz]\n",
    "    \n",
    "    DATA_PSFS.append(scaled_data)  \n",
    "\n",
    "plt.figure(figsize=(17,7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(DATA_PSFS[0], norm = norm_psf)\n",
    "plt.title(\"Data - spider 0deg\")\n",
    "plt.colorbar()\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(DATA_PSFS[1], norm = norm_psf)\n",
    "plt.title(\"Data -spider 270deg\")\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-9\n",
    "\n",
    "optim, opt_state = zdx.get_optimiser(model_sp270, params, optimisers) # all same params as previous fitting\n",
    "progress_bar = tqdm(range(6000), desc='Loss: ')\n",
    "\n",
    "# Run optimisation loop \n",
    "net_losses, Coeffs, Positions, Fluxes = [], [], [], []\n",
    "grads_sp0, grads_sp270, mean_grads = [],[], []\n",
    "models = [model_sp0, model_sp270] # model configurations\n",
    "for i in progress_bar:\n",
    "  grads = None\n",
    "  net_loss = 0\n",
    "  mean_coeff_grads, mean_position_grads, mean_flux_grads = None, None, None # to set initially in loop\n",
    "  for j in range(len(models)):\n",
    "    loss, grads = loss_fn_poisson(model = models[j], data = DATA_PSFS[j])\n",
    "    net_loss += loss \n",
    "\n",
    "    if j == 0:\n",
    "      mean_coeff_grads = grads.aperture.coefficients/len(models)\n",
    "      mean_position_grads = grads.source.position/len(models)\n",
    "      mean_flux_grads = grads.source.flux/len(models)\n",
    "      grads_sp0.append(grads)\n",
    "    else:\n",
    "      mean_coeff_grads += grads.aperture.coefficients/len(models)\n",
    "      mean_position_grads += grads.source.position/len(models)\n",
    "      mean_flux_grads += grads.source.flux/len(models)\n",
    "      grads_sp270.append(grads)\n",
    "\n",
    "  grads = grads.set('aperture.coefficients', mean_coeff_grads)\n",
    "  grads = grads.set('source.position', mean_position_grads)\n",
    "  grads = grads.set('source.flux', mean_flux_grads)\n",
    "  mean_grads.append(grads)\n",
    "\n",
    "  updates, opt_state = optim.update(grads, opt_state)\n",
    "  for j in range(len(models)):\n",
    "    models[j] = zdx.apply_updates(models[j], updates)\n",
    "\n",
    "  net_losses.append(net_loss)\n",
    "  Fluxes.append(models[0].source.flux)\n",
    "  Coeffs.append(models[0].aperture.coefficients)\n",
    "  Positions.append(models[0].source.position)\n",
    "\n",
    "  progress_bar.set_postfix({'Loss': loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(np.array(net_losses))\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Training History\")\n",
    "ax.set_xlabel(\"Training Epoch\")\n",
    "ax.set_ylabel(\"Poisson Log-Likelihood\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 17)\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(np.asarray(Positions)[:,0,0], label=\"Position X\")\n",
    "plt.plot(np.asarray(Positions)[:,0,1], label=\"Position Y\")\n",
    "# plt.plot(np.asarray(Positions)[:,0], label=\"Position X\")\n",
    "# plt.plot(np.asarray(Positions)[:,1], label=\"Position Y\")\n",
    "plt.title(\"Position\")\n",
    "plt.legend()\n",
    "plt.subplot(1,3,2)\n",
    "arr_coeffs = np.asarray(Coeffs)\n",
    "for i in range(len(Coeffs[0])):\n",
    "    label = \"Coeff \" + str(zernike_indicies[i])\n",
    "    plt.plot(arr_coeffs[:,i], label=label)\n",
    "plt.legend()\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(np.asarray(Fluxes))\n",
    "plt.title(\"Flux\")\n",
    "\n",
    "# plot grads \n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "for i in range(len(grads_sp0)):\n",
    "    if i % 500 ==0:\n",
    "        pos_x, pos_y = np.asarray(Positions)[i,0,0], np.asarray(Positions)[i,0,1]\n",
    "        plt.quiver(pos_x,pos_y, grads_sp0[i].source.position[0][0], \n",
    "                   grads_sp0[i].source.position[0][1], color='r',\n",
    "                     width=0.003)#, angles='xy', scale_units='xy', scale=1)#, angles='xy', scale_units='xy', scale=1, color='r')\n",
    "        plt.quiver(pos_x,pos_y, grads_sp270[i].source.position[0][0], \n",
    "                   grads_sp270[i].source.position[0][1], color='g', \n",
    "                    width=0.003)#, angles='xy', scale_units='xy', scale=1, color='g')\n",
    "        plt.quiver(pos_x,pos_y, mean_grads[i].source.position[0][0], \n",
    "                   mean_grads[i].source.position[0][1], color='k', \n",
    "                    width=0.003)#, angles='xy', scale_units='xy', scale=1, color='k')\n",
    "\n",
    "plt.grid()\n",
    "plt.title(\"Position Gradients\")\n",
    "plt.xlabel(\"X-Position\")\n",
    "plt.ylabel(\"Y-Position\")\n",
    "plt.subplot(1,2,2)\n",
    "markers = ['.','o','v','^', '<', '>', 's', 'p', '+', 'd', '*']\n",
    "for i in range(len(grads_sp0)):\n",
    "    if i % 500 ==0:\n",
    "        for j in range(len(Coeffs[0])):\n",
    "            coeff, epoch = arr_coeffs[i,j], i\n",
    "            \n",
    "            plt.plot(epoch, grads_sp0[i].aperture.coefficients[j], marker=markers[j], color='r')\n",
    "            plt.plot(epoch, grads_sp270[i].aperture.coefficients[j], marker=markers[j], color='g')\n",
    "            plt.plot(epoch, mean_grads[i].aperture.coefficients[j], marker=markers[j], color='k')\n",
    "            # plt.quiver(epoch,coeff, grads_sp0[i].aperture.coefficients[j], \n",
    "            #         grads_sp0[i].aperture.coefficients[j], color='r',\n",
    "            #             width=0.003)\n",
    "            # plt.quiver(epoch,coeff, grads_sp270[i].aperture.coefficients[j], \n",
    "            #         grads_sp270[i].aperture.coefficients[j], color='g', \n",
    "            #             width=0.003)\n",
    "            # plt.quiver(epoch,coeff, mean_grads[i].aperture.coefficients[j], \n",
    "            #         mean_grads[i].aperture.coefficients[j], color='k', \n",
    "            #             width=0.003)\n",
    "\n",
    "plt.grid()\n",
    "plt.title(\"Coeff Gradients\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"OPD (m)\")\n",
    "\n",
    "for i, data in enumerate(DATA_PSFS):\n",
    "    plt.figure(figsize=(12,10))\n",
    "    norm_psf = PowerNorm(0.2, vmax=data.max(), vmin=data.min())\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.imshow(data, norm=norm_psf)\n",
    "    plt.colorbar()\n",
    "    plt.title('Data')\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    model_psf = models[i].model()\n",
    "    current_range = model_psf.max() - model_psf.min()\n",
    "    new_range = data.max() - data.min()\n",
    "    model_psf = ( (model_psf - model_psf.min()) * new_range )/current_range + scaled_data.min()\n",
    "    norm_psf = PowerNorm(0.2, vmax=model_psf.max(), vmin=model_psf.min())\n",
    "    mask = np.ones(data.shape)\n",
    "    mask[data < 0.01] = 0\n",
    "    plt.imshow(model_psf*mask, norm=norm_psf)\n",
    "    plt.title('Model')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(2,2,3)\n",
    "    resid = data - model_psf\n",
    "    plt.imshow(resid, cmap='bwr', vmax = np.abs(resid).max(), vmin = -np.abs(resid).max())\n",
    "    plt.colorbar()\n",
    "    plt.title('Residuals')\n",
    "\n",
    "    plt.subplot(2,2,4)\n",
    "    opd = models[i].aperture.eval_basis()\n",
    "    plt.imshow(opd*models[i].aperture.transmission)\n",
    "    plt.title('Retrieved Aberrations')\n",
    "    plt.colorbar()\n",
    "\n",
    "run_coeffs.append(models[0].aperture.coefficients)\n",
    "print(\"Optimised Position: {}\\nFlux: {}\\nCoefficients: {}\".format(models[0].source.position, models[0].source.flux, models[0].aperture.coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i, coeffs in enumerate(run_coeffs):\n",
    "    plt.plot(zernike_indicies,coeffs, label='Run ' + str(i))\n",
    "plt.xlabel('Noll Index')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fisher info for uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toliman_dp_design",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
