{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pupil Gluing Characterisation üñåÔ∏è\n",
    "\n",
    "This notebook:\n",
    "1. Calculates the Zernike coefficients on two separate starphire plates\n",
    "2. Calculates the Zernike coefficients on the glued starphire setup\n",
    "\n",
    "It is helpful to the phase retrieval process that data taken for the non-glued plates and glued setup have the same orientation.\n",
    "\n",
    "Existing system aberrations are loaded and can be calculated using System_Aberrations.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dLux as dl\n",
    "import dLux.utils as dlu\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import jax.random as jr\n",
    "import jax.scipy as jsp\n",
    "from jax import vmap  \n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "jax.config.update(\"jax_debug_nans\", False)\n",
    "jax.config.update('jax_disable_jit', False)\n",
    "\n",
    "import zodiax as zdx\n",
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.filters import window\n",
    "import skimage as ski\n",
    "from skimage.transform import resize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import PowerNorm\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"image.origin\"] = 'lower'\n",
    "plt.rcParams['figure.dpi'] = 72\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "plt.rcParams[\"axes.titlesize\"] = 18\n",
    "plt.rcParams[\"figure.titlesize\"] = 18\n",
    "plt.rcParams[\"axes.labelsize\"] = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Physical Parameters ---------------------------------------------------------------------#\n",
    "aperture_npix = 512           # Number of pixels across the aperture\n",
    "aperture_diameter = 126e-3    # (m)\n",
    "spider_width = 20e-3          # Spider width (m)\n",
    "spider_angle =270             # Spider angle (degrees), clockwise, 0 is spider pointing vertically up\n",
    "coords = dlu.pixel_coords(npixels=aperture_npix, diameter=aperture_diameter)\n",
    "circle = dlu.circle(coords=coords, radius=aperture_diameter/2) \n",
    "\n",
    "# Observations wavelengths (bandpass of 530-640nm)\n",
    "red_laser_wl =  635e-09  # for laser data\n",
    "green_laser_wl = 520e-09  # for laser data\n",
    "wf_npixels = aperture_npix  # Number of pixels across the wavefront\n",
    "wf_diam = aperture_diameter             # Diameter of initial wavefront to propagate wavefront (m)\n",
    "\n",
    "# Detector parameters (BFS-U3-200S6-BD)\n",
    "BFS_px_sep = 2.4e-6 *1e3        # pixel separation (mm)\n",
    "f_det = 1300#1350                    # Focal length from OAP2 to detector (mm) \n",
    "px_ang_sep = 2*np.arctan( (BFS_px_sep/2)/f_det ) # angular sep between pixels (rad)\n",
    "\n",
    "# Simulated Detector\n",
    "psf_npix = 40                 # Number of pixels along one dim of the PSF\n",
    "psf_hlf_sz = int(psf_npix/2)             # half window sz of cropped data\n",
    "oversample = 1                 # Oversampling factor for the PSF\n",
    "psf_pixel_scale = dlu.rad2arcsec(px_ang_sep) # arcsec (to match detector plate scale) 80e-4 \n",
    "\n",
    "# Detector response (gamma curve)\n",
    "# alpha = np.load(\"data/80us_detector/ALPHA_norm.npy\")\n",
    "# beta = np.load(\"data/80us_detector/BETA_norm.npy\")\n",
    "# gamma = np.load(\"data/80us_detector/GAMMA_norm.npy\")\n",
    "alpha = np.load(\"data/500us_detector/ALPHA_norm.npy\")\n",
    "beta = np.load(\"data/500us_detector/BETA_norm.npy\")\n",
    "gamma = np.load(\"data/500us_detector/GAMMA_norm.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the setup, we have a fiber source. \n",
    "# Can model the intensity distribution using a Guassian or can just measure it directly\n",
    "# Measuring directly also captures any mirror imperfections hindering transmission\n",
    "fname = \"data/intensity/15_07_intensity_dist.png\"\n",
    "data = imread(fname, as_gray=True) \n",
    "manual_lim = [1363,4203,386,3214]\n",
    "data = data[manual_lim[2]:manual_lim[3], manual_lim[0]:manual_lim[1]]\n",
    "data = (data - data.min())/(data.max()-data.min())\n",
    "\n",
    "blurred = ski.filters.gaussian(data, sigma=(120, 120))\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(data)\n",
    "plt.title(\"Data - pre-focus\")\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(blurred)\n",
    "plt.title(\"Data blurred\")\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,3)\n",
    "intensity_dist = resize(blurred, (aperture_npix, aperture_npix))\n",
    "intensity_dist = (intensity_dist - intensity_dist.min())/(intensity_dist.max()-intensity_dist.min()) # re-map from 0-1\n",
    "plt.title(\"Blurred re-sized\")\n",
    "plt.imshow(intensity_dist)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### System Aberrations \n",
    "\n",
    "We have an imperfect system. Load in the system aberrations (calculated using System_Aberrations.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_aberr = \"data/spider/retrieval_results/mean_coeffs_combined.npy\"\n",
    "syst_noll = jnp.arange(4, 15) # only first 14 Zernike modes (excluding piston and tip/tilt) are used to classify syst aberrations\n",
    "syst_coeffs = np.load(f_aberr)\n",
    "syst_basis = dlu.zernike_basis(js=syst_noll, diameter=aperture_diameter, coordinates=coords)\n",
    "print(\"System Coefficients (noll {}): {}\".format(syst_noll,syst_coeffs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plate + Spider setup simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zernike aberrations\n",
    "zernike_indicies = jnp.arange(4, 24) \n",
    "coeffs = jnp.zeros(zernike_indicies.shape)\n",
    "basis = dlu.zernike_basis(js=zernike_indicies, coordinates=coords, diameter=aperture_diameter)\n",
    "\n",
    "optical_systems = []\n",
    "transmissions = []\n",
    "\n",
    "# Using PointSources instead of single PointSource object to overcome float grad issue when solving for flux\n",
    "green_src = dl.PointSources(wavelengths=[green_laser_wl], flux =jnp.asarray([1e8],dtype=float))\n",
    "red_src = dl.PointSources(wavelengths=[red_laser_wl], flux =jnp.asarray([1e8],dtype=float))\n",
    "\n",
    "spider_angles = [270, 180] #0deg is spider pointing vertically up, rotates CW from 0deg\n",
    "optical_systems = []\n",
    "transmissions = []\n",
    "for i in range(len(spider_angles)):\n",
    "    spider = dlu.spider(coords=coords, width=spider_width, angles=[spider_angles[i]])\n",
    "    transmission = dlu.combine([circle, spider])*intensity_dist\n",
    "\n",
    "    layers = [\n",
    "        ('SystemAberrations', dl.layers.BasisOptic(basis=syst_basis, coefficients=syst_coeffs, normalise=False)),\n",
    "        ('aperture', dl.layers.BasisOptic(basis=basis, transmission=transmission, coefficients=coeffs, normalise=False)),\n",
    "    ]\n",
    "\n",
    "    optics = dl.AngularOpticalSystem(wf_npixels = wf_npixels, \n",
    "                                diameter=wf_diam, \n",
    "                                layers=layers, \n",
    "                                psf_npixels=psf_npix, \n",
    "                                psf_pixel_scale=psf_pixel_scale,\n",
    "                                oversample=oversample)\n",
    "\n",
    "    optical_systems.append(optics)\n",
    "    transmissions.append(transmission)\n",
    "\n",
    "# Construct Optics\n",
    "optics_sp270  = optical_systems[0]\n",
    "optics_sp180 = optical_systems[1]\n",
    "# Check PSF for aberrated system\n",
    "# layers = [\n",
    "#     ('SystemAberrations', dl.layers.BasisOptic(syst_basis, circle*intensity_dist, syst_coeffs, normalise=False)),\n",
    "# ]\n",
    "\n",
    "# optics = dl.AngularOpticalSystem(wf_npixels = wf_npixels, \n",
    "#                             diameter=wf_diam, \n",
    "#                             layers=layers, \n",
    "#                             psf_npixels=psf_npix, \n",
    "#                             psf_pixel_scale=psf_pixel_scale,\n",
    "#                             oversample=oversample)\n",
    "\n",
    "# psf = optics.propagate_mono(green_laser_wl)\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(psf**0.2)\n",
    "# opd = optics.SystemAberrations.eval_basis()\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(opd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in single Starphire data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    'aperture.coefficients',\n",
    "    'source.position',\n",
    "    'source.flux', \n",
    "    ]\n",
    "\n",
    "learning_rate = 1e-9\n",
    "optimisers = [\n",
    "            optax.adam(learning_rate=learning_rate),\n",
    "            optax.adam(learning_rate=learning_rate),\n",
    "            optax.adam(learning_rate=1e6),\n",
    "              ]\n",
    "\n",
    "@zdx.filter_jit\n",
    "@zdx.filter_value_and_grad(params)\n",
    "def loss_fn_poisson(model, data):\n",
    "\n",
    "    simu_psf = model.model()\n",
    "\n",
    "    loss = -jsp.stats.poisson.logpmf(k=simu_psf, mu=data).sum()\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets loop this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starphire 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location on detector \n",
    "row_start, col_start = 1676, 2600 # Start coord of window on det where data was taken\n",
    "row_len, col_len = 86, 76   # window size of recorded data\n",
    "\n",
    "alpha_cropped = alpha[row_start:row_start+row_len, col_start:col_start+col_len]\n",
    "beta_cropped = beta[row_start:row_start+row_len, col_start:col_start+col_len]\n",
    "gamma_cropped = gamma[row_start:row_start+row_len, col_start:col_start+col_len]\n",
    "\n",
    "# Order in increasing spider angle for each colour separately\n",
    "img_fnames = [\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/non_glued/5_09_starphire1_green_0deg_294us_0gain_img_stack_batch_0.npy\",\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/non_glued/5_09_starphire1_green_90deg_294us_0gain_img_stack_batch_0.npy\",\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/non_glued/5_09_starphire1_red_0deg_133us_0gain_img_stack_batch_0.npy\",\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/non_glued/5_09_starphire1_red_90deg_200us_0gain_img_stack_batch_0.npy\",\n",
    "    \n",
    "]\n",
    "labels = [\n",
    "    \"0deg_green\",\n",
    "    \"90deg_green\",\n",
    "    \"0deg_red\",\n",
    "    \"90deg_red\",\n",
    "]\n",
    "bckgnd_fnames = [\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/non_glued/5_09_starphire1_green_0deg_bckgnd_294us_0gain_img_stack_batch_0.npy\",\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/non_glued/5_09_starphire1_green_90deg_bckgnd_294us_0gain_img_stack_batch_0.npy\",\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/non_glued/5_09_starphire1_green_0deg_bckgnd_294us_0gain_img_stack_batch_0.npy\",\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/non_glued/5_09_starphire1_green_90deg_bckgnd_294us_0gain_img_stack_batch_0.npy\",\n",
    "]\n",
    "still_frame_idxs = [\n",
    "    151, 163, 84, 113 # find_still_frame.py\n",
    "]\n",
    "\n",
    "epochs = [\n",
    "    5000, 5000,5000,5000,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimising on both spider orientations simultaneously "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starphire1_coeffs, starphire1_pos = [], []\n",
    "\n",
    "# 2 loops for 2 diff source colours\n",
    "for i in range(2):\n",
    "    ###---------------------------- Re-init models ----------------------------###\n",
    "    instrument_sp180 = dl.Telescope(optics_sp180, ('source', red_src))\n",
    "    instrument_sp270 = dl.Telescope(optics_sp270, ('source', red_src))\n",
    "\n",
    "    sim_psfs = [instrument_sp180.model(), instrument_sp270.model()]\n",
    "    norm_psfs = [PowerNorm(0.2, vmax=sim_psf.max(), vmin=sim_psf.min()) for sim_psf in sim_psfs]    \n",
    "\n",
    "    ###------------------------------- Get Data -----------------------------###\n",
    "    data_idx = 2*i\n",
    "    data_sp180 = np.load(img_fnames[data_idx])[still_frame_idxs[data_idx],:,:] #assuming only two spider configs, given in order of increasing angle for each colour\n",
    "    data_sp270 = np.load(img_fnames[data_idx+1])[still_frame_idxs[data_idx+1],:,:]\n",
    "    data_list = [data_sp180, data_sp270]\n",
    "    scaled_data_list = []\n",
    "    for j in range(len(data_list)):\n",
    "        data = data_list[j]\n",
    "        bckgnd = np.load(bckgnd_fnames[j])\n",
    "        bckgnd = bckgnd.mean(axis=0)\n",
    "        data = data - bckgnd\n",
    "\n",
    "        # Reverse-model detector response\n",
    "        data_remapped = 0.0 + ((1.0 - 0.0)/(data.max()-data.min()))*(data - data.min()) #[0,1] otput range\n",
    "        data = np.power((data_remapped-np.flip(alpha_cropped))/np.flip(beta_cropped), (1/np.flip(gamma_cropped))) # flip about origin\n",
    "\n",
    "        # Scale intensity\n",
    "        current_range = data.max() - data.min()\n",
    "        new_range = sim_psfs[j].max() - sim_psfs[j].min()\n",
    "        scaled_data = ( (data - data.min()) * new_range )/current_range + sim_psfs[j].min()\n",
    "\n",
    "        psf_center_idx = np.unravel_index(np.argmax(scaled_data, axis=None), scaled_data.shape)\n",
    "        scaled_data = scaled_data[psf_center_idx[0]-psf_hlf_sz:psf_center_idx[0]+psf_hlf_sz,\n",
    "                                    psf_center_idx[1]-psf_hlf_sz:psf_center_idx[1]+psf_hlf_sz]\n",
    "        \n",
    "        scaled_data_list.append(scaled_data)\n",
    "    ###------------------------------- Phase Retrieval -----------------------------###\n",
    "    configs = [instrument_sp180, instrument_sp270]\n",
    "    optim, opt_state = zdx.get_optimiser(instrument_sp180, params, optimisers) # Needs to be iterable param (i.e. accessible via instrument class)\n",
    "\n",
    "    progress_bar = tqdm(range(10000), desc='Loss: ')\n",
    "\n",
    "    # Run optimisation loop \n",
    "    net_losses, Coeffs, Positions_sp180, Positions_sp270, Fluxes= [],[],[],[],[]\n",
    "    for j in progress_bar:\n",
    "        grads = None\n",
    "        net_loss = 0\n",
    "        mean_coeff_grads, mean_position_grads, mean_flux_grads = None, None, None # to set initially in loop\n",
    "        pos_grads = [] # update positional gradients separately (right now I've centered data based on brightest pixel\n",
    "                        # but this is not a super robust method, so allow for source position difference)\n",
    "        for k in range(len(configs)):\n",
    "            loss, grads = loss_fn_poisson(model = configs[k], data = scaled_data_list[k])\n",
    "            net_loss += loss \n",
    "            \n",
    "            if k == 0:\n",
    "                mean_coeff_grads = grads.aperture.coefficients/len(configs)\n",
    "                mean_position_grads = grads.source.position/len(configs)\n",
    "                mean_flux_grads = grads.source.flux/len(configs)\n",
    "            else:\n",
    "                mean_coeff_grads += grads.aperture.coefficients/len(configs)\n",
    "                mean_position_grads += grads.source.position/len(configs)\n",
    "                mean_flux_grads += grads.source.flux/len(configs)\n",
    "\n",
    "            pos_grads.append(grads.source.position)\n",
    "\n",
    "        grads = grads.set('aperture.coefficients', mean_coeff_grads)\n",
    "        grads = grads.set('source.position', mean_position_grads)\n",
    "        grads = grads.set('source.flux', mean_flux_grads)\n",
    "\n",
    "        for k in range(len(configs)):\n",
    "            grads = grads.set('source.position', pos_grads[k])\n",
    "            updates, opt_state = optim.update(grads, opt_state)\n",
    "            configs[k] = zdx.apply_updates(configs[k], updates)\n",
    "\n",
    "        net_losses.append(net_loss)\n",
    "        Fluxes.append(configs[0].source.flux)\n",
    "        Coeffs.append(configs[0].aperture.coefficients)\n",
    "        Positions_sp180.append(configs[0].source.position)\n",
    "        Positions_sp270.append(configs[1].source.position)\n",
    "\n",
    "        progress_bar.set_postfix({'Loss (combined)': net_loss})\n",
    "\n",
    "    ###---------------------------------- Plotting ---------------------------------###\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.subplot(4,3,1)\n",
    "    plt.plot(np.asarray(Positions_sp180)[:,0,0], label=\"Position X - sp180\")\n",
    "    plt.plot(np.asarray(Positions_sp180)[:,0,1], label=\"Position Y - sp180\")\n",
    "    plt.plot(np.asarray(Positions_sp270)[:,0,0], label=\"Position X - sp270\")\n",
    "    plt.plot(np.asarray(Positions_sp270)[:,0,1], label=\"Position Y - sp270\")\n",
    "    plt.title(\"Position\")\n",
    "    plt.legend()\n",
    "    plt.subplot(4,3,2)\n",
    "    arr_coeffs = np.asarray(Coeffs)\n",
    "    for l in range(len(Coeffs[0])):\n",
    "        label = \"Coeff \" + str(zernike_indicies[l])\n",
    "        plt.plot(arr_coeffs[:,l], label=label)\n",
    "    plt.legend()\n",
    "    plt.subplot(4,3,3)\n",
    "    plt.plot(np.asarray(Fluxes))\n",
    "    plt.title(\"Flux\")\n",
    "    plt.subplot(4,3,4)\n",
    "    plt.plot(np.array(net_losses))\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(\"Training History\")\n",
    "    ax.set_xlabel(\"Training Epoch\")\n",
    "    ax.set_ylabel(\"Poisson Log-Likelihood\")\n",
    "\n",
    "    it = 5\n",
    "    for k, config in enumerate(configs):\n",
    "        plt.subplot(4,3,it)\n",
    "        opd = config.aperture.eval_basis()\n",
    "        trans = config.aperture.transmission\n",
    "        plt.imshow(opd*trans, cmap='viridis')\n",
    "        plt.title('Retrieved Aberrations')\n",
    "        plt.colorbar()\n",
    "        it+=1\n",
    "\n",
    "    for k, config in enumerate(configs):\n",
    "        scaled_data = scaled_data_list[k]\n",
    "        instrument = config\n",
    "\n",
    "        plt.subplot(4,3,it)\n",
    "        norm_psf = PowerNorm(0.2, vmax=scaled_data.max(), vmin=scaled_data.min())\n",
    "        plt.imshow(scaled_data, norm=norm_psf)\n",
    "        plt.colorbar()\n",
    "        plt.title('Data - '+labels[data_idx+k])\n",
    "        it+=1\n",
    "\n",
    "        plt.subplot(4,3,it)\n",
    "        model_psf = instrument.model()\n",
    "        current_range = model_psf.max() - model_psf.min()\n",
    "        new_range = scaled_data.max() - scaled_data.min()\n",
    "        model_psf = ( (model_psf - model_psf.min()) * new_range )/current_range + scaled_data.min()\n",
    "        norm_psf = PowerNorm(0.2, vmax=model_psf.max(), vmin=model_psf.min())\n",
    "        mask = np.ones(scaled_data.shape)\n",
    "        mask[scaled_data < 0.01] = 0\n",
    "        plt.imshow(model_psf*mask, norm=norm_psf)\n",
    "        plt.title('Model')\n",
    "        plt.colorbar()\n",
    "        it+=1\n",
    "\n",
    "        plt.subplot(4,3,it)\n",
    "        resid = scaled_data - model_psf\n",
    "        plt.imshow(resid, cmap='bwr', vmax = np.abs(resid).max(), vmin = -np.abs(resid).max())\n",
    "        plt.colorbar()\n",
    "        plt.title('Residuals')\n",
    "        it+=1\n",
    "   \n",
    "    starphire1_coeffs.append(configs[0].aperture.coefficients) # identical coeffs for both configs\n",
    "    starphire1_pos.append([configs[0].source.position, configs[1].source.position])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimising on each spider orientation individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starphire1_coeffs, starphire1_pos = [], []\n",
    "\n",
    "# # no error bars, individual orientation fitting TODO sems all frames - not sure how to do simulatenous opt with mult images\n",
    "# for i in range(len(img_fnames)):\n",
    "#     ###---------------------------- Re-init model ----------------------------###\n",
    "#     if '_0deg_' in img_fnames[i]:\n",
    "#         optics = optics_sp180\n",
    "#     elif '_90deg_' in img_fnames[i]:\n",
    "#         optics = optics_sp270\n",
    "#     else:\n",
    "#         ValueError(\"Unknown File format\")\n",
    "\n",
    "#     if 'green' in img_fnames[i]:\n",
    "#         src = green_src\n",
    "#     elif 'red' in img_fnames[i]:\n",
    "#         src = red_src\n",
    "#     else:\n",
    "#         ValueError(\"Unknown File format\")\n",
    "\n",
    "#     instrument = dl.Telescope(optics, ('source', src))\n",
    "#     sim_psf = instrument.model()\n",
    "#     norm_psf = PowerNorm(0.2, vmax=sim_psf.max(), vmin=sim_psf.min())\n",
    "\n",
    "#     ###------------------------------- Load data -----------------------------###\n",
    "#     data = np.load(img_fnames[i])\n",
    "#     data = data[still_frame_idxs[i],:,:] # using the most still frame (find_still_frame.py)\n",
    "\n",
    "#     bckgnd = np.load(bckgnd_fnames[i])\n",
    "#     bckgnd = np.mean(bckgnd)\n",
    "#     data = data - bckgnd\n",
    "\n",
    "#     data_remapped = 0.0 + ((1.0 - 0.0)/(data.max()-data.min()))*(data - data.min()) #[0,1] otput range\n",
    "#     data_lin = np.power((data_remapped-np.flip(alpha_cropped))/np.flip(beta_cropped), (1/np.flip(gamma_cropped))) # flip about origin\n",
    "\n",
    "#     # Scale intensity\n",
    "#     data = data_lin\n",
    "#     current_range = data.max() - data.min()\n",
    "#     new_range = sim_psf.max() - sim_psf.min()\n",
    "#     scaled_data = ( (data - data.min()) * new_range )/current_range + sim_psf.min()\n",
    "\n",
    "#     psf_center_idx = np.unravel_index(np.argmax(scaled_data, axis=None), scaled_data.shape)\n",
    "#     scaled_data = scaled_data[psf_center_idx[0]-psf_hlf_sz:psf_center_idx[0]+psf_hlf_sz,\n",
    "#                                 psf_center_idx[1]-psf_hlf_sz:psf_center_idx[1]+psf_hlf_sz]\n",
    "\n",
    "#     plt.figure(figsize=(10,5))\n",
    "#     plt.subplot(1,2,1)\n",
    "#     plt.imshow(scaled_data, norm=norm_psf)\n",
    "#     plt.colorbar()\n",
    "#     plt.title(\"Data (scaled)\")\n",
    "#     plt.subplot(1,2,2)\n",
    "#     plt.imshow(sim_psf, norm=norm_psf)\n",
    "#     plt.colorbar()\n",
    "#     plt.title(\"Simulated\")\n",
    "\n",
    "#     ###------------------------------- Phase Retrieval -----------------------------###\n",
    "#     optim, opt_state = zdx.get_optimiser(instrument, params, optimisers) # Needs to be iterable param (i.e. accessible via instrument class)\n",
    "\n",
    "#     progress_bar = tqdm(range(epochs[i]), desc='Loss: ')\n",
    "\n",
    "#     # Run optimisation loop \n",
    "#     net_losses, Coeffs, Positions, Fluxes= [],[],[],[]\n",
    "#     for j in progress_bar:\n",
    "#         poiss_loss, poiss_grads = loss_fn_poisson(model = instrument, data = scaled_data)\n",
    "\n",
    "#         updates, opt_state = optim.update(poiss_grads, opt_state)\n",
    "#         instrument = zdx.apply_updates(instrument, updates) \n",
    "\n",
    "#         net_losses.append(poiss_loss)\n",
    "#         Fluxes.append(instrument.source.flux)\n",
    "#         Coeffs.append(instrument.aperture.coefficients)\n",
    "#         Positions.append(instrument.source.position)\n",
    "\n",
    "#         progress_bar.set_postfix({'Loss': poiss_loss})\n",
    "#     ###---------------------------------- Plotting ---------------------------------###\n",
    "#     plt.figure(figsize=(11,3))\n",
    "#     plt.subplot(1,4,1)\n",
    "#     plt.plot(np.asarray(Positions)[:,0,0], label=\"Position X\")\n",
    "#     plt.plot(np.asarray(Positions)[:,0,1], label=\"Position Y\")\n",
    "#     plt.title(\"Position\")\n",
    "#     plt.legend()\n",
    "#     plt.subplot(1,4,2)\n",
    "#     arr_coeffs = np.asarray(Coeffs)\n",
    "#     for k in range(len(Coeffs[0])):\n",
    "#         label = \"Coeff \" + str(zernike_indicies[k])\n",
    "#         plt.plot(arr_coeffs[:,k], label=label)\n",
    "#     plt.legend()\n",
    "#     plt.subplot(1,4,3)\n",
    "#     plt.plot(np.asarray(Fluxes))\n",
    "#     plt.title(\"Flux\")\n",
    "#     plt.subplot(1,4,4)\n",
    "#     plt.plot(np.array(net_losses))\n",
    "#     ax = plt.gca()\n",
    "#     ax.set_title(\"Training History\")\n",
    "#     ax.set_xlabel(\"Training Epoch\")\n",
    "#     ax.set_ylabel(\"Poisson Log-Likelihood\")\n",
    "\n",
    "\n",
    "#     plt.figure(figsize=(12,10))\n",
    "#     norm_psf = PowerNorm(0.2, vmax=scaled_data.max(), vmin=scaled_data.min())\n",
    "#     plt.subplot(2,2,1)\n",
    "#     plt.imshow(scaled_data, norm=norm_psf)\n",
    "#     plt.colorbar()\n",
    "#     plt.title('Data')\n",
    "\n",
    "#     plt.subplot(2,2,2)\n",
    "#     model_psf = instrument.model()\n",
    "#     current_range = model_psf.max() - model_psf.min()\n",
    "#     new_range = scaled_data.max() - scaled_data.min()\n",
    "#     model_psf = ( (model_psf - model_psf.min()) * new_range )/current_range + scaled_data.min()\n",
    "#     norm_psf = PowerNorm(0.2, vmax=model_psf.max(), vmin=model_psf.min())\n",
    "#     mask = np.ones(scaled_data.shape)\n",
    "#     mask[scaled_data < 0.01] = 0\n",
    "#     plt.imshow(model_psf*mask, norm=norm_psf)\n",
    "#     plt.title('Model')\n",
    "#     plt.colorbar()\n",
    "\n",
    "#     plt.subplot(2,2,3)\n",
    "#     resid = scaled_data - model_psf\n",
    "#     plt.imshow(resid, cmap='bwr', vmax = np.abs(resid).max(), vmin = -np.abs(resid).max())\n",
    "#     plt.colorbar()\n",
    "#     plt.title('Residuals')\n",
    "\n",
    "#     plt.subplot(2,2,4)\n",
    "#     opd = instrument.aperture.eval_basis()\n",
    "#     transmission = instrument.aperture.transmission \n",
    "#     plt.imshow(opd*transmission, cmap='viridis')\n",
    "#     plt.title('Retrieved Aberrations')\n",
    "#     plt.colorbar()\n",
    "\n",
    "\n",
    "#     print(\"Optimised Position: {}\\nFlux: {}\\nCoefficients: {}\".format(instrument.source.position, instrument.source.flux, instrument.aperture.coefficients))\n",
    "\n",
    "#     starphire1_coeffs.append(instrument.aperture.coefficients)\n",
    "#     starphire1_pos.append(instrument.source.position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot \n",
    "# WFE calc excluding piston, tip and tilt\n",
    "plt.figure(figsize=(10,5))\n",
    "wf_errs = []\n",
    "labels = ['green', 'red']\n",
    "# OR (depending on optimisation config)\n",
    "# labels = [\n",
    "#     \"0deg_green\",\n",
    "#     \"90deg_green\",\n",
    "#     \"0deg_red\",\n",
    "#     \"90deg_red\",\n",
    "# ]\n",
    "for i,coeffs in enumerate(starphire1_coeffs):\n",
    "\n",
    "    if 'red' in labels[i]:\n",
    "        wl = red_laser_wl\n",
    "        colour = 'r'\n",
    "    elif 'green' in labels[i]:\n",
    "        wl = green_laser_wl\n",
    "        colour = 'g'\n",
    "    else:\n",
    "        ValueError(\"Unknown Wavelength\")\n",
    "\n",
    "    plt.scatter(zernike_indicies, coeffs, label=labels[i], c=colour)\n",
    "    RMS_wf_err = ((coeffs**2).sum())**0.5\n",
    "\n",
    "    print(\"{} RMS WFE: {:.3f}lambda\".format(labels[i], RMS_wf_err/wl))\n",
    "    wf_errs.append(RMS_wf_err/wl) \n",
    "\n",
    "plt.xlabel(\"Zernike Noll Index\")\n",
    "plt.ylabel(\"Coefficient (m)\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "print(\"Mean RMS WFE: {:.3f}lambda\".format(np.mean(wf_errs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Zernike coeff uncertainties once sure this is calc correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starphire 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_fnames = [\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/non_glued/5_09_starphire2_green_0deg_80us_0gain_img_stack_batch_0.npy\",\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/non_glued/5_09_starphire2_green_90deg_80us_0gain_img_stack_batch_0.npy\",\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/non_glued/5_09_starphire2_red_0deg_120us_0gain_img_stack_batch_0.npy\",\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/non_glued/5_09_starphire2_red_90deg_80us_0gain_img_stack_batch_0.npy\",\n",
    "    \n",
    "]\n",
    "labels = [\n",
    "    \"0deg_green\",\n",
    "    \"90deg_green\",\n",
    "    \"0deg_red\",\n",
    "    \"90deg_red\",\n",
    "]\n",
    "bckgnd_fnames = [\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/non_glued/5_09_starphire2_green_0deg_bckgnd_80us_0gain_img_stack_batch_0.npy\",\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/non_glued/5_09_starphire2_green_90deg_bckgnd_80us_0gain_img_stack_batch_0.npy\",\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/non_glued/5_09_starphire2_green_0deg_bckgnd_80us_0gain_img_stack_batch_0.npy\",\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/non_glued/5_09_starphire2_green_90deg_bckgnd_80us_0gain_img_stack_batch_0.npy\",\n",
    "]\n",
    "still_frame_idxs = [\n",
    "    151, 163, 84, 113 # find_still_frame.py\n",
    "]\n",
    "\n",
    "epochs = [\n",
    "    5000, 5000,5000,5000,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starphire2_coeffs, starphire2_pos = [], []\n",
    "\n",
    "# no error bars, individual orientation fitting TODO sems all frames - not sure how to do simulatenous opt with mult images\n",
    "for i in range(len(img_fnames)):\n",
    "    ###---------------------------- Re-init model ----------------------------###\n",
    "    if '_0deg_' in img_fnames[i]:\n",
    "        optics = optics_sp180\n",
    "    elif '_90deg_' in img_fnames[i]:\n",
    "        optics = optics_sp270\n",
    "    else:\n",
    "        ValueError(\"Unknown File format\")\n",
    "\n",
    "    if 'green' in img_fnames[i]:\n",
    "        src = green_src\n",
    "    elif 'red' in img_fnames[i]:\n",
    "        src = red_src\n",
    "    else:\n",
    "        ValueError(\"Unknown File format\")\n",
    "\n",
    "    instrument = dl.Telescope(optics, ('source', src))\n",
    "    sim_psf = instrument.model()\n",
    "    norm_psf = PowerNorm(0.2, vmax=sim_psf.max(), vmin=sim_psf.min())\n",
    "\n",
    "    ###------------------------------- Load data -----------------------------###\n",
    "    data = np.load(img_fnames[i])\n",
    "    data = data[still_frame_idxs[i],:,:] # using the most still frame (find_still_frame.py)\n",
    "\n",
    "    bckgnd = np.load(bckgnd_fnames[i])\n",
    "    bckgnd = np.mean(bckgnd)\n",
    "    data = data - bckgnd\n",
    "\n",
    "    data_remapped = 0.0 + ((1.0 - 0.0)/(data.max()-data.min()))*(data - data.min()) #[0,1] otput range\n",
    "    data_lin = np.power((data_remapped-np.flip(alpha_cropped))/np.flip(beta_cropped), (1/np.flip(gamma_cropped))) # flip about origin\n",
    "\n",
    "    # Scale intensity\n",
    "    data = data_lin\n",
    "    current_range = data.max() - data.min()\n",
    "    new_range = sim_psf.max() - sim_psf.min()\n",
    "    scaled_data = ( (data - data.min()) * new_range )/current_range + sim_psf.min()\n",
    "\n",
    "    psf_center_idx = np.unravel_index(np.argmax(scaled_data, axis=None), scaled_data.shape)\n",
    "    scaled_data = scaled_data[psf_center_idx[0]-psf_hlf_sz:psf_center_idx[0]+psf_hlf_sz,\n",
    "                                psf_center_idx[1]-psf_hlf_sz:psf_center_idx[1]+psf_hlf_sz]\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(scaled_data, norm=norm_psf)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Data (scaled)\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(sim_psf, norm=norm_psf)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Simulated\")\n",
    "\n",
    "    ###------------------------------- Phase Retrieval -----------------------------###\n",
    "    optim, opt_state = zdx.get_optimiser(instrument, params, optimisers) # Needs to be iterable param (i.e. accessible via instrument class)\n",
    "\n",
    "    progress_bar = tqdm(range(epochs[i]), desc='Loss: ')\n",
    "\n",
    "    # Run optimisation loop \n",
    "    net_losses, Coeffs, Positions, Fluxes= [],[],[],[]\n",
    "    for j in progress_bar:\n",
    "        poiss_loss, poiss_grads = loss_fn_poisson(model = instrument, data = scaled_data)\n",
    "\n",
    "        updates, opt_state = optim.update(poiss_grads, opt_state)\n",
    "        instrument = zdx.apply_updates(instrument, updates) \n",
    "\n",
    "        net_losses.append(poiss_loss)\n",
    "        Fluxes.append(instrument.source.flux)\n",
    "        Coeffs.append(instrument.aperture.coefficients)\n",
    "        Positions.append(instrument.source.position)\n",
    "\n",
    "        progress_bar.set_postfix({'Loss': poiss_loss})\n",
    "    ###---------------------------------- Plotting ---------------------------------###\n",
    "    plt.figure(figsize=(11,3))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.plot(np.asarray(Positions)[:,0,0], label=\"Position X\")\n",
    "    plt.plot(np.asarray(Positions)[:,0,1], label=\"Position Y\")\n",
    "    plt.title(\"Position\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1,4,2)\n",
    "    arr_coeffs = np.asarray(Coeffs)\n",
    "    for k in range(len(Coeffs[0])):\n",
    "        label = \"Coeff \" + str(zernike_indicies[k])\n",
    "        plt.plot(arr_coeffs[:,k], label=label)\n",
    "    plt.legend()\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.plot(np.asarray(Fluxes))\n",
    "    plt.title(\"Flux\")\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.plot(np.array(net_losses))\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(\"Training History\")\n",
    "    ax.set_xlabel(\"Training Epoch\")\n",
    "    ax.set_ylabel(\"Poisson Log-Likelihood\")\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12,10))\n",
    "    norm_psf = PowerNorm(0.2, vmax=scaled_data.max(), vmin=scaled_data.min())\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.imshow(scaled_data, norm=norm_psf)\n",
    "    plt.colorbar()\n",
    "    plt.title('Data')\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    model_psf = instrument.model()\n",
    "    current_range = model_psf.max() - model_psf.min()\n",
    "    new_range = scaled_data.max() - scaled_data.min()\n",
    "    model_psf = ( (model_psf - model_psf.min()) * new_range )/current_range + scaled_data.min()\n",
    "    norm_psf = PowerNorm(0.2, vmax=model_psf.max(), vmin=model_psf.min())\n",
    "    mask = np.ones(scaled_data.shape)\n",
    "    mask[scaled_data < 0.01] = 0\n",
    "    plt.imshow(model_psf*mask, norm=norm_psf)\n",
    "    plt.title('Model')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(2,2,3)\n",
    "    resid = scaled_data - model_psf\n",
    "    plt.imshow(resid, cmap='bwr', vmax = np.abs(resid).max(), vmin = -np.abs(resid).max())\n",
    "    plt.colorbar()\n",
    "    plt.title('Residuals')\n",
    "\n",
    "    plt.subplot(2,2,4)\n",
    "    opd = instrument.aperture.eval_basis()\n",
    "    transmission = instrument.aperture.transmission\n",
    "    plt.imshow(opd*transmission, cmap='viridis')\n",
    "    plt.title('Retrieved Aberrations')\n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "    print(\"Optimised Position: {}\\nFlux: {}\\nCoefficients: {}\".format(instrument.source.position, instrument.source.flux, instrument.aperture.coefficients))\n",
    "\n",
    "    starphire2_coeffs.append(instrument.aperture.coefficients)\n",
    "    starphire2_pos.append(instrument.source.position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot \n",
    "# WFE calc excluding piston, tip and tilt\n",
    "plt.figure(figsize=(10,5))\n",
    "wf_errs = []\n",
    "for i,coeffs in enumerate(starphire2_coeffs):\n",
    "    plt.scatter(zernike_indicies, coeffs, label=labels[i])\n",
    "    RMS_wf_err = ((coeffs**2).sum())**0.5\n",
    "\n",
    "    if 'red' in labels[i]:\n",
    "        wl = red_laser_wl\n",
    "    elif 'green' in labels[i]:\n",
    "        wl = green_laser_wl\n",
    "    else:\n",
    "        ValueError(\"Unknown Wavelength\")\n",
    "\n",
    "    print(\"{} RMS WFE: {:.3f}lambda\".format(labels[i], RMS_wf_err/wl))\n",
    "    wf_errs.append(RMS_wf_err/wl) \n",
    "\n",
    "plt.xlabel(\"Zernike Noll Index\")\n",
    "plt.ylabel(\"Coefficient (m)\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "print(\"Mean RMS WFE: {:.3f}lambda\".format(np.mean(wf_errs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Green Data\")\n",
    "plt.plot(zernike_indicies, green_coeffs[1]/green_laser_wl, label=\"Starphire 1\")\n",
    "plt.plot(zernike_indicies, green_coeffs[2]/green_laser_wl, label=\"Starphire 2\")\n",
    "plt.plot(zernike_indicies, (green_coeffs[1]+green_coeffs[2])/green_laser_wl, label=\"1+2\")\n",
    "plt.xlabel(\"Zernike Noll Index\")\n",
    "plt.ylabel(\"OPD (multiple of wl)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Red Data\")\n",
    "plt.plot(zernike_indicies, red_coeffs[1]/red_laser_wl, label=\"Starphire 1\")\n",
    "plt.plot(zernike_indicies, red_coeffs[2]/red_laser_wl, label=\"Starphire 2\")\n",
    "plt.plot(zernike_indicies, (red_coeffs[1]+red_coeffs[2])/red_laser_wl, label=\"1+2\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"Zernike Noll Index\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glued plates\n",
    "\n",
    "Will need to simulate with both spider setups again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-init sim with bigger fov\n",
    "# Simulated Detector\n",
    "psf_npix = 150                 # Number of pixels along one dim of the PSF\n",
    "psf_hlf_sz = int(psf_npix/2)   # half window sz of cropped data\n",
    "\n",
    "# Construct Optics\n",
    "optics = dl.AngularOpticalSystem(wf_npixels = wf_npixels, \n",
    "                                diameter=wf_diam, \n",
    "                                layers=layers, \n",
    "                                psf_npixels=psf_npix, \n",
    "                                psf_pixel_scale=psf_pixel_scale,\n",
    "                                oversample=oversample)\n",
    "\n",
    "\n",
    "instrument = dl.Telescope(optics, ('source', src))\n",
    "sim_psf = instrument.model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location on detector \n",
    "row_start, col_start = 1670, 2580 # Start coord of window on det where data was taken\n",
    "row_len, col_len =500,500   # window size of recorded data\n",
    "\n",
    "alpha_cropped = alpha[row_start:row_start+row_len, col_start:col_start+col_len]\n",
    "beta_cropped = beta[row_start:row_start+row_len, col_start:col_start+col_len]\n",
    "gamma_cropped = gamma[row_start:row_start+row_len, col_start:col_start+col_len]\n",
    "\n",
    "img_fnames = [\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/glued/15_08_green_149us_19.5gain_img_stack_batch_0.npy\",\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/glued/15_08_red_149us_19.5gain_img_stack_batch_0.npy\",\n",
    "]\n",
    "bckgnd_fnames = [\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/glued/15_08_bckgnd_149us_19.5gain_img_stack_batch_0.npy\",\n",
    "    \"/Volumes/Morgana2/gpir9156/toliman/glued/15_08_bckgnd_149us_19.5gain_img_stack_batch_0.npy\",\n",
    "]\n",
    "still_frame_idxs = [\n",
    "    32,36 # find_still_frame.py\n",
    "]\n",
    "epochs = [\n",
    "    10000, 5000\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_glued_coeffs = None\n",
    "red_glued_coeffs = None\n",
    "\n",
    "for i in range(len(img_fnames)):\n",
    "    ###---------------------------- Re-init model ----------------------------###\n",
    "    instrument = dl.Telescope(optics, ('source', src))\n",
    "    sim_psf = instrument.model()\n",
    "\n",
    "    ###------------------------------- Load data -----------------------------###\n",
    "    data = np.load(img_fnames[i])\n",
    "    data = data[still_frame_idxs[i],:,:] # using the most still frame (find_still_frame.py)\n",
    "\n",
    "    bckgnd = np.load(bckgnd_fnames[i])\n",
    "    bckgnd = np.mean(bckgnd)\n",
    "    data = data - bckgnd\n",
    "\n",
    "    data_remapped = 0.0 + ((1.0 - 0.0)/(data.max()-data.min()))*(data - data.min()) #[0,1] otput range\n",
    "    data_lin = np.power((data_remapped-np.flip(alpha_cropped))/np.flip(beta_cropped), (1/np.flip(gamma_cropped))) # flip about origin\n",
    "\n",
    "    # Scale intensity\n",
    "    data = data_lin\n",
    "    current_range = data.max() - data.min()\n",
    "    new_range = sim_psf.max() - sim_psf.min()\n",
    "    scaled_data = ( (data - data.min()) * new_range )/current_range + sim_psf.min()\n",
    "\n",
    "    psf_center_idx = np.unravel_index(np.argmax(scaled_data, axis=None), scaled_data.shape)\n",
    "    scaled_data = scaled_data[psf_center_idx[0]-psf_hlf_sz:psf_center_idx[0]+psf_hlf_sz,\n",
    "                                psf_center_idx[1]-psf_hlf_sz:psf_center_idx[1]+psf_hlf_sz]\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(scaled_data, norm=norm_psf)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Data (scaled)\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(sim_psf, norm=norm_psf)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Simulated\")\n",
    "\n",
    "    ###------------------------------- Phase Retrieval -----------------------------###\n",
    "    optim, opt_state = zdx.get_optimiser(instrument, params, optimisers) # Needs to be iterable param (i.e. accessible via instrument class)\n",
    "\n",
    "    progress_bar = tqdm(range(epochs[i]), desc='Loss: ')\n",
    "\n",
    "    # Run optimisation loop \n",
    "    net_losses, Coeffs, Positions, Fluxes= [],[],[],[]\n",
    "    for j in progress_bar:\n",
    "        poiss_loss, poiss_grads = loss_fn_poisson(model = instrument, data = scaled_data)\n",
    "\n",
    "        updates, opt_state = optim.update(poiss_grads, opt_state)\n",
    "        instrument = zdx.apply_updates(instrument, updates) \n",
    "\n",
    "        net_losses.append(poiss_loss)\n",
    "        Fluxes.append(instrument.source.flux)\n",
    "        Coeffs.append(instrument.aperture.coefficients)\n",
    "        Positions.append(instrument.source.position)\n",
    "\n",
    "        progress_bar.set_postfix({'Loss': poiss_loss})\n",
    "    ###---------------------------------- Plotting ---------------------------------###\n",
    "    plt.figure(figsize=(11,3))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.plot(np.asarray(Positions)[:,0,0], label=\"Position X\")\n",
    "    plt.plot(np.asarray(Positions)[:,0,1], label=\"Position Y\")\n",
    "    plt.title(\"Position\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1,4,2)\n",
    "    arr_coeffs = np.asarray(Coeffs)\n",
    "    for k in range(len(Coeffs[0])):\n",
    "        label = \"Coeff \" + str(zernike_indicies[k])\n",
    "    plt.plot(arr_coeffs[:,k], label=label)\n",
    "    plt.legend()\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.plot(np.asarray(Fluxes))\n",
    "    plt.title(\"Flux\")\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.plot(np.array(net_losses))\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(\"Training History\")\n",
    "    ax.set_xlabel(\"Training Epoch\")\n",
    "    ax.set_ylabel(\"Poisson Log-Likelihood\")\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12,10))\n",
    "    norm_psf = PowerNorm(0.2, vmax=scaled_data.max(), vmin=scaled_data.min())\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.imshow(scaled_data, norm=norm_psf)\n",
    "    plt.colorbar()\n",
    "    plt.title('Data')\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    model_psf = instrument.model()\n",
    "    current_range = model_psf.max() - model_psf.min()\n",
    "    new_range = scaled_data.max() - scaled_data.min()\n",
    "    model_psf = ( (model_psf - model_psf.min()) * new_range )/current_range + scaled_data.min()\n",
    "    norm_psf = PowerNorm(0.2, vmax=model_psf.max(), vmin=model_psf.min())\n",
    "    mask = np.ones(scaled_data.shape)\n",
    "    mask[scaled_data < 0.01] = 0\n",
    "    plt.imshow(model_psf*mask, norm=norm_psf)\n",
    "    plt.title('Model')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(2,2,3)\n",
    "    resid = scaled_data - model_psf\n",
    "    plt.imshow(resid, cmap='bwr', vmax = np.abs(resid).max(), vmin = -np.abs(resid).max())\n",
    "    plt.colorbar()\n",
    "    plt.title('Residuals')\n",
    "\n",
    "    plt.subplot(2,2,4)\n",
    "    opd = instrument.aperture.eval_basis()\n",
    "    plt.imshow(opd*transmission, cmap='viridis')\n",
    "    plt.title('Retrieved Aberrations')\n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "    print(\"Optimised Position: {}\\nFlux: {}\\nCoefficients: {}\".format(instrument.source.position, instrument.source.flux, instrument.aperture.coefficients))\n",
    "\n",
    "    if 'green' in img_fnames[i]:\n",
    "        green_glued_coeffs = instrument.aperture.coefficients\n",
    "    elif 'red' in img_fnames[i]:\n",
    "        red_glued_coeffs = instrument.aperture.coefficients\n",
    "    else:\n",
    "        ValueError(\"Unknown wavel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coeffs comparison\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Green Data\")\n",
    "plt.plot(zernike_indicies, green_glued_coeffs/green_laser_wl, label=\"Glued\")\n",
    "plt.plot(zernike_indicies, (green_coeffs[1]+green_coeffs[2])/green_laser_wl, label=\"1+2\")\n",
    "plt.xlabel(\"Zernike Noll Index\")\n",
    "plt.ylabel(\"OPD (multiple of wl)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Red Data\")\n",
    "plt.plot(zernike_indicies, red_glued_coeffs/red_laser_wl, label=\"Glued\")\n",
    "plt.plot(zernike_indicies, (red_coeffs[1]+red_coeffs[2])/red_laser_wl, label=\"1+2\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"Zernike Noll Index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSF comparsion (just one colour for now)\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(11,10))\n",
    "plt.suptitle(\"Green\")\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Model (Glued)\")\n",
    "instrument = dl.Telescope(optics, ('source', src))\n",
    "instrument = instrument.set('aperture.coefficients', green_glued_coeffs)\n",
    "model_psf = instrument.model()\n",
    "norm_psf = PowerNorm(0.2, vmax=model_psf.max(), vmin=model_psf.min())\n",
    "plt.imshow(model_psf, norm=norm_psf)\n",
    "plt.colorbar(label=\"Intensity\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "opd = instrument.aperture.eval_basis()\n",
    "plt.imshow(opd/green_laser_wl)\n",
    "plt.colorbar(label=\"OPD (multiple of wl)\")\n",
    "\n",
    "RMS_wf_err0 = ((green_glued_coeffs**2).sum())**0.5\n",
    "print(\"Glued wf error: {}lambda\".format(RMS_wf_err0/green_laser_wl))\n",
    "RMS_wf_err1 = ((green_coeffs[1]**2).sum())**0.5\n",
    "RMS_wf_err2 = ((green_coeffs[2]**2).sum())**0.5\n",
    "print(\"Starphire 1: {}lambda, Starphire 2: {}lambda\".format(RMS_wf_err1/green_laser_wl, RMS_wf_err2/green_laser_wl))\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Model (Ideal Glued)\")\n",
    "instrument = dl.Telescope(optics, ('source', src))\n",
    "tot_z = green_coeffs[1]+green_coeffs[2]\n",
    "instrument = instrument.set('aperture.coefficients', tot_z)\n",
    "model_psf = instrument.model()\n",
    "norm_psf = PowerNorm(0.2, vmax=model_psf.max(), vmin=model_psf.min())\n",
    "plt.imshow(model_psf, norm=norm_psf)\n",
    "plt.colorbar(label=\"Intensity\")\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "opd = instrument.aperture.eval_basis()\n",
    "plt.imshow(opd/green_laser_wl)\n",
    "plt.colorbar(label=\"OPD (multiple of wl)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toliman_dp_design",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
